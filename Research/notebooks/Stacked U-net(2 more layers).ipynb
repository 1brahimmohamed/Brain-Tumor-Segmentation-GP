{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7161487,"sourceType":"datasetVersion","datasetId":4136399}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-26T20:54:42.137521Z","iopub.execute_input":"2024-02-26T20:54:42.138618Z","iopub.status.idle":"2024-02-26T20:54:42.146038Z","shell.execute_reply.started":"2024-02-26T20:54:42.138578Z","shell.execute_reply":"2024-02-26T20:54:42.144655Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import os\nimport subprocess\nimport nibabel as nib\nimport tensorflow as tf\nfrom skimage import exposure\nfrom math import ceil\nimport matplotlib.pyplot as plt\nimport random\n\nclass DataLoader:\n    def __init__(self, data_path, split_ratio, batch_size=None):\n        self.data_path = data_path\n        self.split_ratio = split_ratio\n        self.all_subjects = None\n        self.subjects_lists = []\n        self.labels = {'train': 0, 'test': 1, 'validation': 2}\n        self.size = [0, 0, 0]\n        self.batch_size = batch_size\n        self.slices_number = None\n\n    def list_subjects(self):\n        subjects = os.listdir(self.data_path)\n        subjects = [item for item in subjects if item.startswith('sub')]\n        self.all_subjects = subjects\n\n    def get_nifti_path(self, subject, number_of_motion='1'):\n        ref_path_stand = f'{self.data_path}/{subject}/anat/{subject}_acq-standard_T1w.nii/'\n        select_path_stand = subprocess.run(['ls', ref_path_stand], capture_output=True, text=True).stdout.replace(\"\\n\", \"\")\n\n        ref_path_motion = f'{self.data_path}/{subject}/anat/{subject}_acq-headmotion{number_of_motion}_T1w.nii/'\n        select_path_motion = subprocess.run(['ls', ref_path_motion], capture_output=True, text=True).stdout.replace(\"\\n\", \"\")\n\n        return [ref_path_stand + select_path_stand, ref_path_motion + select_path_motion]\n\n    def get_paired_volumes(self, path):\n        if os.path.exists(path[0]) and os.path.exists(path[1]):\n            free_data = nib.load(path[0]).get_fdata()\n#             free_data = exposure.rescale_intensity(free_data, out_range=(0.0, 1.0))\n            free_data = exposure.rescale_intensity(free_data, out_range=(-1.0, 1.0))\n\n            motion_data = nib.load(path[1]).get_fdata()\n#             motion_data = exposure.rescale_intensity(motion_data, out_range=(0.0, 1.0))\n            motion_data = exposure.rescale_intensity(motion_data, out_range=(-1.0, 1.0))\n            return tf.convert_to_tensor(free_data), tf.convert_to_tensor(motion_data)\n        else:\n            return None, None\n\n    def split_data(self):\n        self.list_subjects()\n        if ceil(sum(self.split_ratio)) == 1 and len(self.split_ratio) <= 3:\n            self.split_ratio.insert(0, 0)\n            cumulative_sum = [sum(self.split_ratio[:i + 1]) for i in range(len(self.split_ratio))]\n            number_of_subjects = len(self.all_subjects)\n\n            for i in range(1, len(self.split_ratio)):\n                self.subjects_lists.append(\n                    self.all_subjects[int(round(cumulative_sum[i - 1] * number_of_subjects)):int(\n                        round(cumulative_sum[i] * number_of_subjects))])\n\n                self.size[i - 1] = len(self.subjects_lists[i - 1])  * 2 * 190\n\n                if i - 1 == 0:\n                    self.size[i - 1] -= 8  * 2 * 190\n        else:\n            print(\"The Summation of ratios is not equal to 1\")\n       \n    def generator(self, mode):\n        subjects = self.subjects_lists[self.labels[mode]]\n\n        def data_gen():\n            for subject in subjects:\n                for i in range(2):\n                    pathes = self.get_nifti_path(subject, str(i + 1))\n                    free, motion = self.get_paired_volumes(pathes)\n                    if motion is not None:\n                        self.slices_number = motion.shape[0]\n\n                        for slice_id in range(0, self.slices_number):\n                            start_idx = slice_id + 1\n                            end_idx = (slice_id + 1) + 1\n                            if (end_idx < self.slices_number-1):\n                                free_slice = free[start_idx:end_idx]\n                                free_slice = tf.transpose(free_slice, perm=[1, 2, 0])\n                                \n                                motion_slice = motion[start_idx:end_idx]\n                                motion_slice = tf.transpose(motion_slice, perm=[1, 2, 0])\n                                \n                                motion_before_slice = motion[start_idx-1:end_idx-1]\n                                motion_before_slice = tf.transpose(motion_before_slice, perm=[1, 2, 0])\n                                \n                                motion_after_slice = motion[start_idx+1:end_idx+1]\n                                motion_after_slice = tf.transpose(motion_after_slice, perm=[1, 2, 0])\n\n                                yield (\n                                (motion_before_slice, motion_slice, motion_after_slice),\n                                free_slice\n                                )\n\n        input_signature = (\n            (tf.TensorSpec(shape=(256, 256, 1), dtype=tf.float32),\n             tf.TensorSpec(shape=(256, 256, 1), dtype=tf.float32),\n             tf.TensorSpec(shape=(256, 256, 1), dtype=tf.float32)),\n            tf.TensorSpec(shape=(256, 256, 1), dtype=tf.float32)\n        )\n\n        dataset = tf.data.Dataset.from_generator(data_gen, output_signature=input_signature)\n        dataset = dataset.batch(self.batch_size)\n\n        return dataset","metadata":{"execution":{"iopub.status.busy":"2024-02-26T20:54:42.191612Z","iopub.execute_input":"2024-02-26T20:54:42.191973Z","iopub.status.idle":"2024-02-26T20:54:55.050475Z","shell.execute_reply.started":"2024-02-26T20:54:42.191947Z","shell.execute_reply":"2024-02-26T20:54:55.049515Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-02-26 20:54:44.373414: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-26 20:54:44.373543: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-26 20:54:44.515902: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"def create_center_rectangle_mask(mask_shape, rect_height, rect_width):\n    mask_shape = mask_shape[1:]\n    # Create a mask with a central rectangle of zeros\n    mask = np.ones(mask_shape, dtype=np.float32)\n\n    # Calculate the position of the top-left corner of the rectangle\n    rect_top = (mask_shape[0] - rect_height) // 2\n    rect_left = (mask_shape[1] - rect_width) // 2\n\n    # Update the mask with the rectangle at the center\n    mask[rect_top:rect_top+rect_height, rect_left:rect_left+rect_width,:] = 0\n\n    # Convert the NumPy array to a TensorFlow tensor\n    mask_tensor = tf.convert_to_tensor(mask, dtype=tf.float32)\n\n    return mask_tensor\n\ndef crop_center_rectangle_mask(tensor, rect_height=50, rect_width=100):\n    mask = create_center_rectangle_mask(tensor.shape, rect_height, rect_height)\n    return tf.multiply(tensor, mask)","metadata":{"execution":{"iopub.status.busy":"2024-02-26T20:54:55.052038Z","iopub.execute_input":"2024-02-26T20:54:55.052587Z","iopub.status.idle":"2024-02-26T20:54:55.059590Z","shell.execute_reply.started":"2024-02-26T20:54:55.052561Z","shell.execute_reply":"2024-02-26T20:54:55.058525Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import keras\nimport tensorflow as tf\nfrom tensorflow.keras.models import *\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras import layers\nimport tensorflow.keras.backend as K\nimport numpy as np\n\nIMAGE_ORDERING_CHANNELS_LAST = \"channels_last\"\nIMAGE_ORDERING_CHANNELS_FIRST = \"channels_first\"\n\n# Default IMAGE_ORDERING = channels_last\nIMAGE_ORDERING = IMAGE_ORDERING_CHANNELS_LAST\n\nif IMAGE_ORDERING == 'channels_first':\n\tMERGE_AXIS = 1\nelif IMAGE_ORDERING == 'channels_last':\n\tMERGE_AXIS = -1\n\n# CBAM --------------------------------------------\n# Convolutional Block Attention Module(CBAM) block\ndef cbam_block(cbam_feature, ratio=8):\n\tcbam_feature = channel_attention(cbam_feature, ratio)\n\tcbam_feature = spatial_attention(cbam_feature)\n\treturn cbam_feature\n\ndef channel_attention(input_feature, ratio=8):\n\n\tchannel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n\tchannel = input_feature.shape[channel_axis]  # input_feature._keras_shape[channel_axis]\n\n\tshared_layer_one = Dense(channel//ratio,\n\t\t\t\t\t\t\t activation='relu',\n\t\t\t\t\t\t\t kernel_initializer='he_normal',\n\t\t\t\t\t\t\t use_bias=True,\n\t\t\t\t\t\t\t bias_initializer='zeros')\n\tshared_layer_two = Dense(channel,\n\t\t\t\t\t\t\t kernel_initializer='he_normal',\n\t\t\t\t\t\t\t use_bias=True,\n\t\t\t\t\t\t\t bias_initializer='zeros')\n\n\tavg_pool = GlobalAveragePooling2D()(input_feature)\n\tavg_pool = Reshape((1,1,channel))(avg_pool)\n\tassert avg_pool.shape[1:] == (1,1,channel)\n\tavg_pool = shared_layer_one(avg_pool)\n\tassert avg_pool.shape[1:] == (1,1,channel//ratio)\n\tavg_pool = shared_layer_two(avg_pool)\n\tassert avg_pool.shape[1:] == (1,1,channel)\n\n\tmax_pool = GlobalMaxPooling2D()(input_feature)\n\tmax_pool = Reshape((1,1,channel))(max_pool)\n\tassert max_pool.shape[1:] == (1,1,channel)\n\tmax_pool = shared_layer_one(max_pool)\n\tassert max_pool.shape[1:] == (1,1,channel//ratio)\n\tmax_pool = shared_layer_two(max_pool)\n\tassert max_pool.shape[1:] == (1,1,channel)\n\n\tcbam_feature = Add()([avg_pool,max_pool])\n\tcbam_feature = Activation('sigmoid')(cbam_feature)\n\n\tif K.image_data_format() == \"channels_first\":\n\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n\n\treturn multiply([input_feature, cbam_feature])\n\ndef spatial_attention(input_feature):\n\tkernel_size = 7\n\n\tif K.image_data_format() == \"channels_first\":\n\t\tchannel = input_feature._keras_shape[1]\n\t\tcbam_feature = Permute((2,3,1))(input_feature)\n\telse:\n\t\tchannel = input_feature.shape[-1]\n\t\tcbam_feature = input_feature\n\n\tavg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n\tassert avg_pool.shape[-1] == 1\n\tmax_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n\tassert max_pool.shape[-1] == 1\n\tconcat = Concatenate(axis=3)([avg_pool, max_pool])\n\tassert concat.shape[-1] == 2\n\tcbam_feature = Conv2D(filters = 1,\n\t\t\t\t\tkernel_size=kernel_size,\n\t\t\t\t\tstrides=1,\n\t\t\t\t\tpadding='same',\n\t\t\t\t\tactivation='sigmoid',\n\t\t\t\t\tkernel_initializer='he_normal',\n\t\t\t\t\tuse_bias=False)(concat)\n\tassert cbam_feature.shape[-1] == 1\n\n\tif K.image_data_format() == \"channels_first\":\n\t\tcbam_feature = Permute((3, 1, 2))(cbam_feature)\n\n\treturn multiply([input_feature, cbam_feature])\n\ndef UNet(img_input):\n\tk1 = 32\n\tk2 = 64\n\tk3 = 128\n\tk4 = 256\n\tk5 = 512\n\tk6 = 1024\n\t# Block 1 in Contracting Path\n\tconv1 = Conv2D(k1, (3, 3), data_format=IMAGE_ORDERING,padding='same', dilation_rate=1)(img_input)\n\tconv1 = BatchNormalization()(conv1)\n\tconv1 = Activation(tf.nn.leaky_relu)(conv1)\n\t#conv1 = Dropout(0.2)(conv1)\n\tconv1 = Conv2D(k1, (3, 3), data_format=IMAGE_ORDERING, padding='same', dilation_rate=1)(conv1)\n\tconv1 = BatchNormalization()(conv1)\n\tconv1 = Activation(tf.nn.leaky_relu)(conv1)\n\n\tconv1 = cbam_block(conv1)    # Convolutional Block Attention Module(CBAM) block\n\n\to = AveragePooling2D((2, 2), strides=(2, 2))(conv1)\n\n\t# Block 2 in Contracting Path\n\tconv2 = Conv2D(k2, (3, 3), data_format=IMAGE_ORDERING, padding='same', dilation_rate=1)(o)\n\tconv2 = BatchNormalization()(conv2)\n\tconv2 = Activation(tf.nn.leaky_relu)(conv2)\n\tconv2 = Dropout(0.2)(conv2)\n\tconv2 = Conv2D(k2, (3, 3), data_format=IMAGE_ORDERING, padding='same', dilation_rate=1)(conv2)\n\tconv2 = BatchNormalization()(conv2)\n\tconv2 = Activation(tf.nn.leaky_relu)(conv2)\n\n\tconv2 = cbam_block(conv2)    # Convolutional Block Attention Module(CBAM) block\n\n\to = AveragePooling2D((2, 2), strides=(2, 2))(conv2)\n\n\t# Block 3 in Contracting Path\n\tconv3 = Conv2D(k3, (3, 3), data_format=IMAGE_ORDERING, padding='same', dilation_rate=1)(o)\n\tconv3 = BatchNormalization()(conv3)\n\tconv3 = Activation(tf.nn.leaky_relu)(conv3)\n\t#conv3 = Dropout(0.2)(conv3)\n\tconv3 = Conv2D(k3, (3, 3), data_format=IMAGE_ORDERING, padding='same', dilation_rate=1)(conv3)\n\tconv3 = BatchNormalization()(conv3)\n\tconv3 = Activation(tf.nn.leaky_relu)(conv3)\n\n\tconv3 = cbam_block(conv3)    # Convolutional Block Attention Module(CBAM) block\n\n\to = AveragePooling2D((2, 2), strides=(2, 2))(conv3)\n\n\t # Transition layer between contracting and expansive paths:\n\tconv4 = Conv2D(k4, (3, 3), data_format=IMAGE_ORDERING, padding='same', dilation_rate=1)(o)\n\tconv4 = BatchNormalization()(conv4)\n\tconv4 = Activation(tf.nn.leaky_relu)(conv4)\n\t#conv4 = Dropout(0.2)(conv4)\n\tconv4 = Conv2D(k4, (3, 3), data_format=IMAGE_ORDERING, padding='same', dilation_rate=1)(conv4)\n\tconv4 = BatchNormalization()(conv4)\n\tconv4 =Activation(tf.nn.leaky_relu)(conv4)\n\n\tconv4 = cbam_block(conv4)    # Convolutional Block Attention Module(CBAM) block\n### New added Part (additional layers of model) \n\to = AveragePooling2D((2, 2), strides=(2, 2))(conv4)\n    \n\tconv5 = Conv2D(k5, (3, 3), data_format=IMAGE_ORDERING, padding='same', dilation_rate=1)(o)\n\tconv5 = BatchNormalization()(conv5)\n\tconv5 = Activation(tf.nn.leaky_relu)(conv5)\n\t#conv3 = Dropout(0.2)(conv3)\n\tconv5 = Conv2D(k5, (3, 3), data_format=IMAGE_ORDERING, padding='same', dilation_rate=1)(conv5)\n\tconv5 = BatchNormalization()(conv5)\n\tconv5 = Activation(tf.nn.leaky_relu)(conv5)\n\n\tconv5 = cbam_block(conv5)    # Convolutional Block Attention Module(CBAM) block\n\n\to = AveragePooling2D((2, 2), strides=(2, 2))(conv5)\n    \n\tconv6 = Conv2D(k6, (3, 3), data_format=IMAGE_ORDERING, padding='same', dilation_rate=1)(o)\n\tconv6 = BatchNormalization()(conv6)\n\tconv6 = Activation(tf.nn.leaky_relu)(conv6)\n\t#conv3 = Dropout(0.2)(conv3)\n\tconv6 = Conv2D(k5, (3, 3), data_format=IMAGE_ORDERING, padding='same', dilation_rate=1)(conv6)\n\tconv6 = BatchNormalization()(conv6)\n\tconv6 = Activation(tf.nn.leaky_relu)(conv6)\n\n\tconv6 = cbam_block(conv6)    # Convolutional Block Attention Module(CBAM) block\n\n\t# Block 1 in Expansive Path\n\tup1 = UpSampling2D((2, 2), data_format=IMAGE_ORDERING)(conv6)\n\tup1 = concatenate([up1, conv5], axis=MERGE_AXIS)\n\tdeconv1 =  Conv2D(k5, (3, 3), data_format=IMAGE_ORDERING, padding='same', dilation_rate=1)(up1)\n\tdeconv1 = BatchNormalization()(deconv1)\n\tdeconv1 = Activation(tf.nn.leaky_relu)(deconv1)\n\t#deconv1 = Dropout(0.2)(deconv1)\n\tdeconv1 =  Conv2D(k5, (3, 3), data_format=IMAGE_ORDERING, padding='same', dilation_rate=1)(deconv1)\n\tdeconv1 = BatchNormalization()(deconv1)\n\tdeconv1 = Activation(tf.nn.leaky_relu)(deconv1)\n\n\tdeconv1 = cbam_block(deconv1)    # Convolutional Block Attention Module(CBAM) block\n\n\t# Block 2 in Expansive Path\n\tup2 = UpSampling2D((2, 2), data_format=IMAGE_ORDERING)(deconv1)\n\tup2 = concatenate([up2, conv4], axis=MERGE_AXIS)\n\tdeconv2 = Conv2D(k4, (3, 3), data_format=IMAGE_ORDERING, padding='same', dilation_rate=1)(up2)\n\tdeconv2 = BatchNormalization()(deconv2)\n\tdeconv2 = Activation(tf.nn.leaky_relu)(deconv2)\n\t#deconv2 = Dropout(0.2)(deconv2)\n\tdeconv2 = Conv2D(k4, (3, 3), data_format=IMAGE_ORDERING, padding='same', dilation_rate=1)(deconv2)\n\tdeconv2 = BatchNormalization()(deconv2)\n\tdeconv2 = Activation(tf.nn.leaky_relu)(deconv2)\n\n\tdeconv2 = cbam_block(deconv2)    # Convolutional Block Attention Module(CBAM) block\n\n\t# Block 3 in Expansive Path\n\tup3 = UpSampling2D((2, 2), data_format=IMAGE_ORDERING)(deconv2)\n\tup3 = concatenate([up3, conv3], axis=MERGE_AXIS)\n\tdeconv3 = Conv2D(k3, (3, 3), data_format=IMAGE_ORDERING, padding='same', dilation_rate=1)(up3)\n\tdeconv3 = BatchNormalization()(deconv3)\n\tdeconv3 = Activation(tf.nn.leaky_relu)(deconv3)\n\t#deconv3 = Dropout(0.2)(deconv3)\n\tdeconv3 = Conv2D(k3, (3, 3), data_format=IMAGE_ORDERING, padding='same', dilation_rate=1)(deconv3)\n\tdeconv3 = BatchNormalization()(deconv3)\n\tdeconv3 = Activation(tf.nn.leaky_relu)(deconv3)\n\t ## This is added part to model\n        \n\tdeconv4 = cbam_block(deconv3)\n    # Convolutional Block Attention Module(CBAM) block\n\tup4 = UpSampling2D((2, 2), data_format=IMAGE_ORDERING)(deconv3)\n\tup4 = concatenate([up4, conv2], axis=MERGE_AXIS)\n\tdeconv4 = Conv2D(k2, (3, 3), data_format=IMAGE_ORDERING, padding='same', dilation_rate=1)(up4)\n\tdeconv4 = BatchNormalization()(deconv4)\n\tdeconv4 = Activation(tf.nn.leaky_relu)(deconv4)\n\t#deconv3 = Dropout(0.2)(deconv3)\n\tdeconv4 = Conv2D(k2, (3, 3), data_format=IMAGE_ORDERING, padding='same', dilation_rate=1)(deconv4)\n\tdeconv4 = BatchNormalization()(deconv4)\n\tdeconv4 = Activation(tf.nn.leaky_relu)(deconv4)\n\n\tdeconv4 = cbam_block(deconv4)# Convolutional Block Attention Module(CBAM) block\n    \n\tup5 = UpSampling2D((2, 2), data_format=IMAGE_ORDERING)(deconv4)\n\tup5 = concatenate([up5, conv1], axis=MERGE_AXIS)\n\tdeconv5 = Conv2D(k1, (3, 3), data_format=IMAGE_ORDERING, padding='same', dilation_rate=1)(up5)\n\tdeconv5 = BatchNormalization()(deconv5)\n\tdeconv5 = Activation(tf.nn.leaky_relu)(deconv5)\n\t#deconv3 = Dropout(0.2)(deconv3)\n\tdeconv5 = Conv2D(k1, (3, 3), data_format=IMAGE_ORDERING, padding='same', dilation_rate=1)(deconv5)\n\tdeconv5 = BatchNormalization()(deconv5)\n\tdeconv5 = Activation(tf.nn.leaky_relu)(deconv5)\n\n\tdeconv5 = cbam_block(deconv5)\n\n\toutput = Conv2D(1, (3, 3), data_format=IMAGE_ORDERING, padding='same')(deconv5)\n# \toutput = Activation('sigmoid')(output)\n\toutput = Activation('tanh')(output)\n\treturn output\n\ndef Correction_Multi_input(input_height, input_width):\n\tassert input_height % 32 == 0\n\tassert input_width % 32 == 0\n\n#   UNET\n\timg_input_1 = Input(shape=(input_height, input_width, 1))\n\timg_input_2 = Input(shape=(input_height, input_width, 1))\n\timg_input_3 = Input(shape=(input_height, input_width, 1))\n# \tkk = 32\n\tkk = 64\n\tconv1 = Conv2D(kk, (3, 3), data_format=IMAGE_ORDERING,padding='same', dilation_rate=1)(img_input_1) # dilation_rate=6\n\tconv1 = BatchNormalization()(conv1)\n\tconv1 = Activation('relu')(conv1)\n\tconv2 = Conv2D(kk, (3, 3), data_format=IMAGE_ORDERING,padding='same', dilation_rate=1)(img_input_2) # dilation_rate=6\n\tconv2 = BatchNormalization()(conv2)\n\tconv2 = Activation('relu')(conv2)\n\tconv3 = Conv2D(kk, (3, 3), data_format=IMAGE_ORDERING,padding='same', dilation_rate=1)(img_input_3) # dilation_rate=6\n\tconv3 = BatchNormalization()(conv3)\n\tconv3 = Activation('relu')(conv3)\n\n\tinput_concat = concatenate([conv1, conv2, conv3], axis=MERGE_AXIS)  #conv4\n\t# dataset = tf.data.Dataset.from_tensor_slices((img_input_1, img_input_2, img_input_3)\n\n\t## Two Stacked Nets:\n\tpred_1  = UNet(input_concat)\n\tinput_2 = concatenate([input_concat, pred_1], axis=MERGE_AXIS)\n\tpred_2  = UNet(input_2) #\n\n\tmodel = Model(inputs=[img_input_1,img_input_2,img_input_3], outputs=pred_2)\n\n\n\treturn model","metadata":{"execution":{"iopub.status.busy":"2024-02-26T20:59:30.090375Z","iopub.execute_input":"2024-02-26T20:59:30.090738Z","iopub.status.idle":"2024-02-26T20:59:30.142168Z","shell.execute_reply.started":"2024-02-26T20:59:30.090710Z","shell.execute_reply":"2024-02-26T20:59:30.141354Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\nimport math\nimport pandas as pd\nfrom tensorflow.keras.models import model_from_json\n\n# Constants\nTRAIN = 1  # True False\nTEST = 0  # True False\nNB_EPOCH = 20\nLEARNING_RATE = 0.001  # 0.001 (default)\nHEIGHT, WIDTH = 256, 256\nPREDICTION_PATH = '/kaggle/working/Prediction'\nWEIGHTS_PATH = '/kaggle/working/Weights'\n\nprint('Reading Data ... ')\ndata_path = \"/kaggle/input/mahmoud-dataset\"\nsplit_ratio = [0.7, 0.2, 0.1]\n# split_ratio = [0.03, 0.92, 0.03]\nbatch_size = 14\n\ndata_loader = DataLoader(data_path, split_ratio, batch_size)\ndata_loader.split_data()\n\ntrain_dataset = data_loader.generator('train')\ntest_dataset = data_loader.generator('test')\nvalidation_dataset = data_loader.generator('validation')","metadata":{"execution":{"iopub.status.busy":"2024-02-26T20:59:30.426354Z","iopub.execute_input":"2024-02-26T20:59:30.427150Z","iopub.status.idle":"2024-02-26T20:59:30.517292Z","shell.execute_reply.started":"2024-02-26T20:59:30.427121Z","shell.execute_reply":"2024-02-26T20:59:30.516220Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Reading Data ... \n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Model\n\ndef ssim_score(y_true, y_pred):\n    score = tf.reduce_mean(tf.image.ssim(y_true, y_pred, 2.0))\n    return score\n\ndef ssim_loss(y_true, y_pred):\n    loss_ssim = 1.0 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 2.0))\n    return loss_ssim\n\ndef l2_loss(y_true, y_pred):\n    \"\"\"\n    Computes the L2 loss between the ground truth and predicted tensors.\n\n    Parameters:\n        y_true (tf.Tensor): Ground truth tensor.\n        y_pred (tf.Tensor): Predicted tensor.\n\n    Returns:\n        tf.Tensor: Normalized L2 loss.\n\n    This function calculates the mean squared error (MSE) between the ground truth\n    and predicted tensors. It then reduces the MSE along the spatial dimensions,\n    typically representing the height and width of the tensors, resulting in a\n    tensor of shape (batch_size,), where each element represents the mean MSE\n    for a single sample in the batch.\n\n    The loss is then normalized using L2 normalization to ensure that it falls\n    within the range of 0 to 1. Finally, the mean of the normalized loss across\n    the batch is computed and returned.\n    \"\"\"\n    mse = tf.keras.losses.mean_squared_error(y_true, y_pred)\n\n    # Reduce on spatial information\n    batch_mse = tf.reduce_mean(mse, axis=(1, 2))\n\n    # Normalize the loss function to be between 0 and 1\n    normalized_loss = tf.nn.l2_normalize(batch_mse, axis=-1)\n    \n    # Compute the mean of the normalized loss across the batch\n    normalized_reduced_loss = tf.reduce_mean(batch_mse)\n\n    return normalized_reduced_loss\n\ndef spatial_fft_loss(y_true, y_pred):\n    \"\"\"\n    Custom loss function for spatial loss with FFT features.\n\n    Args:\n        y_true: Ground truth image(s).\n        y_pred: Predicted image(s).\n\n    Returns:\n        Normalized reduced spatial loss.\n\n    This function defines a custom loss for training neural networks. It applies a Fourier Transform\n    to the true and predicted images, extracts the real and imaginary parts of the transformed\n    features, and calculates the mean squared error between them. The loss is then normalized and\n    reduced to a single scalar value.\n\n    \"\"\"\n    # Apply Fourier Transform to the true and predicted images\n    true_fft = tf.signal.fft2d(tf.cast(y_true, dtype=tf.complex64))\n    pred_fft = tf.signal.fft2d(tf.cast(y_pred, dtype=tf.complex64))\n\n    # Extract Real & Imaginary parts\n    true_fft_real = tf.math.real(true_fft)\n    true_fft_imag = tf.math.imag(true_fft)\n    pred_fft_real = tf.math.real(pred_fft)\n    pred_fft_imag = tf.math.imag(pred_fft)\n\n    # Crop center rectangles for real and imag\n    true_fft_real_cropped = crop_center_rectangle_mask(true_fft_real)\n    true_fft_imag_cropped = crop_center_rectangle_mask(true_fft_imag)\n    pred_fft_real_cropped = crop_center_rectangle_mask(pred_fft_real)\n    pred_fft_imag_cropped = crop_center_rectangle_mask(pred_fft_imag)\n\n    # Calculate L2 loss\n    mse_real = tf.keras.losses.mean_squared_error(true_fft_real_cropped, pred_fft_real_cropped)\n    mse_imag = tf.keras.losses.mean_squared_error(true_fft_imag_cropped, pred_fft_imag_cropped)\n\n    # Total L2 loss\n    total_loss = 0.5 * (mse_real + mse_imag)\n    \n    # Reduce on spatial information\n    batch_loss = tf.reduce_mean(total_loss, axis=(1, 2))\n    \n    # Normalize the loss function to be between 0 and 1\n    normalized_loss = tf.nn.l2_normalize(batch_loss, axis=-1)\n\n    normalized_reduced_loss = tf.reduce_mean(normalized_loss)\n\n    return normalized_reduced_loss\n\nimport tensorflow as tf\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Model\n\ndef init_vgg16_model(perceptual_layer_name='block3_conv3'):\n    \"\"\"\n    Initialize a pre-trained VGG16 model for feature extraction.\n\n    Args:\n        perceptual_layer_name: Name of the layer to extract features from.\n\n    Returns:\n        Pre-trained VGG16 model with specified layer for feature extraction.\n\n    This function loads a pre-trained VGG16 model with ImageNet weights and removes the top\n    classification layers. It then extracts the specified layer for feature extraction and\n    freezes the model's layers to prevent further training.\n\n    \"\"\"\n    # Load pre-trained VGG16 model without the top classification layers\n    vgg_model = VGG16(include_top=False, weights='imagenet', input_shape=(256, 256, 3))\n\n    # Extract the specified layer from the VGG16 model\n    perceptual_model = Model(inputs=vgg_model.input, outputs=vgg_model.get_layer(perceptual_layer_name).output)\n\n    # Freeze the layers in the perceptual model so they are not trained further\n    for layer in perceptual_model.layers:\n        layer.trainable = False\n        \n    print(\"VGG16 Model Initialized\")\n    return perceptual_model\n\n# Initialize VGG16 model for feature extraction\nperceptual_model = init_vgg16_model()\n\ndef perceptual_fft_loss(y_true, y_pred):\n    \"\"\"\n    Custom loss function for perceptual loss with FFT features.\n\n    Args:\n        y_true: Ground truth image(s).\n        y_pred: Predicted image(s).\n\n    Returns:\n        Normalized reduced perceptual loss.\n\n    This function defines a custom loss for training neural networks. It extracts features from\n    true and predicted images using a pre-trained VGG16 model, applies a Fourier Transform to these\n    features, and calculates the mean squared error between the real and imaginary parts of the\n    transformed features. The loss is then normalized and reduced to a single scalar value.\n\n    \"\"\"\n    # Convert single-channel images to RGB\n    y_true_rgb = tf.repeat(y_true, 3, axis=-1)\n    y_pred_rgb = tf.repeat(y_pred, 3, axis=-1)\n\n    # Preprocess images for VGG16\n    y_true_processed = tf.keras.applications.vgg16.preprocess_input(y_true_rgb)\n    y_pred_processed = tf.keras.applications.vgg16.preprocess_input(y_pred_rgb)\n\n    # Extract features from specified layer for true and predicted images\n    features_true = perceptual_model(y_true_processed)\n    features_pred = perceptual_model(y_pred_processed)\n\n    # Apply Fourier Transform to the true and predicted images\n    true_fft = tf.signal.fft2d(tf.cast(features_true, dtype=tf.complex64))\n    pred_fft = tf.signal.fft2d(tf.cast(features_pred, dtype=tf.complex64))\n\n    # Extract Real & Imaginary parts\n    true_fft_real = tf.math.real(true_fft)\n    true_fft_imag = tf.math.imag(true_fft)\n    pred_fft_real = tf.math.real(pred_fft)\n    pred_fft_imag = tf.math.imag(pred_fft)\n\n    # Crop center rectangles for real and imag\n    true_fft_real_cropped = crop_center_rectangle_mask(true_fft_real)\n    true_fft_imag_cropped = crop_center_rectangle_mask(true_fft_imag)\n    pred_fft_real_cropped = crop_center_rectangle_mask(pred_fft_real)\n    pred_fft_imag_cropped = crop_center_rectangle_mask(pred_fft_imag)\n\n    # Calculate L2 loss\n    mse_real = tf.keras.losses.mean_squared_error(true_fft_real_cropped, pred_fft_real_cropped)\n    mse_imag = tf.keras.losses.mean_squared_error(true_fft_imag_cropped, pred_fft_imag_cropped)\n\n    # Total L2 loss\n    total_loss = 0.5 * (mse_real + mse_imag)\n    \n    # Reduce on spatial information\n    batch_loss = tf.reduce_mean(total_loss, axis=(1, 2))\n    \n    # Normalize the loss function to be between 0 and 1\n    normalized_loss = tf.nn.l2_normalize(batch_loss, axis=-1)\n\n    normalized_reduced_loss = tf.reduce_mean(normalized_loss)\n\n    return normalized_reduced_loss\n\ndef perceptual_loss(y_true, y_pred):\n    \"\"\"\n    Custom loss function for perceptual loss.\n\n    Args:\n        y_true: Ground truth image(s).\n        y_pred: Predicted image(s).\n\n    Returns:\n        Normalized reduced perceptual loss.\n\n    This function defines a custom loss for training neural networks. It converts single-channel\n    images to RGB, preprocesses them for VGG16, and extracts features from a specified layer\n    using a pre-trained VGG16 model. It then calculates the mean squared error between the features\n    of the true and predicted images. The loss is normalized and reduced to a single scalar value.\n\n    \"\"\"\n    # Convert single-channel images to RGB\n    y_true_rgb = tf.repeat(y_true, 3, axis=-1)\n    y_pred_rgb = tf.repeat(y_pred, 3, axis=-1)\n\n    # Preprocess images for VGG16\n    y_true_processed = tf.keras.applications.vgg16.preprocess_input(y_true_rgb)\n    y_pred_processed = tf.keras.applications.vgg16.preprocess_input(y_pred_rgb)\n\n    # Extract features from specified layer for true and predicted images\n    features_true = perceptual_model(y_true_processed)\n    features_pred = perceptual_model(y_pred_processed)\n\n    # Calculate L2 loss\n    mse = tf.keras.losses.mean_squared_error(features_true, features_pred)\n\n    # Reduce on spatial information\n    batch_loss = tf.reduce_mean(mse, axis=(1, 2))\n    \n    # Normalize the loss function to be between 0 and 1\n    normalized_loss = tf.nn.l2_normalize(batch_loss, axis=-1)\n\n    normalized_reduced_loss = tf.reduce_mean(normalized_loss)\n\n    return normalized_reduced_loss\n\ndef psnr(y_true, y_pred):\n    return tf.reduce_mean(-tf.image.psnr(y_true, y_pred, max_val=2.0))  # Adjust max_val for data normalized between -1 and 1\n\ndef total_loss(y_true, y_pred):\n    return l2_loss(y_true, y_pred)\n#     return (1/2)*(spatial_fft_loss(y_true, y_pred)+ssim_loss(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2024-02-26T20:59:31.418432Z","iopub.execute_input":"2024-02-26T20:59:31.418780Z","iopub.status.idle":"2024-02-26T20:59:31.791353Z","shell.execute_reply.started":"2024-02-26T20:59:31.418756Z","shell.execute_reply":"2024-02-26T20:59:31.790333Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"VGG16 Model Initialized\n","output_type":"stream"}]},{"cell_type":"code","source":"import math\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import CSVLogger, LearningRateScheduler, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import model_from_json\n\ndef save_model(path_weight, model, md='lstm'):\n    model_json = model.to_json()\n    with open(f\"{path_weight}model_{md}.json\", \"w\") as json_file:\n        json_file.write(model_json)\n    model.save(f\"{path_weight}model_{md}.h5\")\n    print(\"The model is successfully saved\")\n\n\ndef load_model(path_weight, md='lstm', custom_objects=None):\n    json_file = open(f\"{path_weight}model_{md}.json\", 'r')\n    loaded_model_json = json_file.read()\n    json_file.close()\n    loaded_model = model_from_json(loaded_model_json, custom_objects=custom_objects)\n    loaded_model.load_weights(f\"{path_weight}model_{md}.h5\")\n    print(\"Loaded model from disk\")\n    return loaded_model\n\n\ndef scheduler(epoch):\n    ep = 10\n    if epoch < ep:\n        return LEARNING_RATE\n    else:\n        return LEARNING_RATE * math.exp(0.1 * (ep - epoch))\n\n\ndef main():\n    if TRAIN:\n        print('---------------------------------')\n        print('Model Training ...')\n        print('---------------------------------')\n        model = Correction_Multi_input(HEIGHT, WIDTH)\n        print(model.summary())\n#         # Define the path to the model file\n#         model_path = \"/kaggle/working/stacked_model_fft_01_val_loss_0.2138.h5\"\n#         # Load the model with custom loss function\n#         model = tf.keras.models.load_model(model_path, custom_objects={'total_loss': total_loss,\n#                                                                       'ssim_score': ssim_score})\n\n        csv_logger = CSVLogger(f'{WEIGHTS_PATH}_Loss_Acc.csv', append=True, separator=',')\n        reduce_lr = LearningRateScheduler(scheduler)\n        model.compile(loss=ssim_loss, optimizer=Adam(learning_rate=LEARNING_RATE),\n                      metrics=[ssim_score, 'mse', psnr])\n        \n        checkpoint_path = '/kaggle/working/stacked_model_more_layers_{epoch:02d}_val_loss_{val_loss:.4f}.h5'\n        model_checkpoint = ModelCheckpoint(checkpoint_path,\n                                   monitor='val_loss',\n                                   save_best_only=False,\n                                   save_weights_only=False,\n                                   mode='min',\n                                   verbose=1)\n        \n        hist = model.fit(train_dataset,\n                         epochs=NB_EPOCH,\n#                          steps_per_epoch=data_loader.size[0] // batch_size,\n                         verbose=1,\n                         validation_data=validation_dataset,\n#                          validation_steps=data_loader.size[2] // batch_size,\n                         callbacks=[csv_logger, reduce_lr, model_checkpoint])\n\n    if TEST:\n        print('========================================Load Model-s Weights=====================================')\n        custom_objects = {'ssim_loss': ssim_loss, 'ssim_score': ssim_score}\n        model = load_model(WEIGHTS_PATH, 'lstm', custom_objects=custom_objects)\n        print('---------------------------------')\n        print('Evaluate Model on Testing Set ...')\n        print('---------------------------------')\n        pred = model.predict(test_dataset,\n                             steps=data_loader.size[1] // batch_size)\n        print('==================================')\n        print('Predictions=', pred.shape)\n        print('==================================')\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2024-02-26T21:14:24.036565Z","iopub.execute_input":"2024-02-26T21:14:24.037161Z","iopub.status.idle":"2024-02-26T21:15:23.060039Z","shell.execute_reply.started":"2024-02-26T21:14:24.037128Z","shell.execute_reply":"2024-02-26T21:15:23.058686Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"---------------------------------\nModel Training ...\n---------------------------------\nModel: \"model_3\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_9 (InputLayer)        [(None, 256, 256, 1)]        0         []                            \n                                                                                                  \n input_10 (InputLayer)       [(None, 256, 256, 1)]        0         []                            \n                                                                                                  \n input_11 (InputLayer)       [(None, 256, 256, 1)]        0         []                            \n                                                                                                  \n conv2d_100 (Conv2D)         (None, 256, 256, 64)         640       ['input_9[0][0]']             \n                                                                                                  \n conv2d_101 (Conv2D)         (None, 256, 256, 64)         640       ['input_10[0][0]']            \n                                                                                                  \n conv2d_102 (Conv2D)         (None, 256, 256, 64)         640       ['input_11[0][0]']            \n                                                                                                  \n batch_normalization_68 (Ba  (None, 256, 256, 64)         256       ['conv2d_100[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_69 (Ba  (None, 256, 256, 64)         256       ['conv2d_101[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n batch_normalization_70 (Ba  (None, 256, 256, 64)         256       ['conv2d_102[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_100 (Activation  (None, 256, 256, 64)         0         ['batch_normalization_68[0][0]\n )                                                                  ']                            \n                                                                                                  \n activation_101 (Activation  (None, 256, 256, 64)         0         ['batch_normalization_69[0][0]\n )                                                                  ']                            \n                                                                                                  \n activation_102 (Activation  (None, 256, 256, 64)         0         ['batch_normalization_70[0][0]\n )                                                                  ']                            \n                                                                                                  \n concatenate_46 (Concatenat  (None, 256, 256, 192)        0         ['activation_100[0][0]',      \n e)                                                                  'activation_101[0][0]',      \n                                                                     'activation_102[0][0]']      \n                                                                                                  \n conv2d_103 (Conv2D)         (None, 256, 256, 32)         55328     ['concatenate_46[0][0]']      \n                                                                                                  \n batch_normalization_71 (Ba  (None, 256, 256, 32)         128       ['conv2d_103[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_103 (Activation  (None, 256, 256, 32)         0         ['batch_normalization_71[0][0]\n )                                                                  ']                            \n                                                                                                  \n conv2d_104 (Conv2D)         (None, 256, 256, 32)         9248      ['activation_103[0][0]']      \n                                                                                                  \n batch_normalization_72 (Ba  (None, 256, 256, 32)         128       ['conv2d_104[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_104 (Activation  (None, 256, 256, 32)         0         ['batch_normalization_72[0][0]\n )                                                                  ']                            \n                                                                                                  \n global_average_pooling2d_3  (None, 32)                   0         ['activation_104[0][0]']      \n 0 (GlobalAveragePooling2D)                                                                       \n                                                                                                  \n global_max_pooling2d_30 (G  (None, 32)                   0         ['activation_104[0][0]']      \n lobalMaxPooling2D)                                                                               \n                                                                                                  \n reshape_60 (Reshape)        (None, 1, 1, 32)             0         ['global_average_pooling2d_30[\n                                                                    0][0]']                       \n                                                                                                  \n reshape_61 (Reshape)        (None, 1, 1, 32)             0         ['global_max_pooling2d_30[0][0\n                                                                    ]']                           \n                                                                                                  \n dense_60 (Dense)            (None, 1, 1, 4)              132       ['reshape_60[0][0]',          \n                                                                     'reshape_61[0][0]']          \n                                                                                                  \n dense_61 (Dense)            (None, 1, 1, 32)             160       ['dense_60[0][0]',            \n                                                                     'dense_60[1][0]']            \n                                                                                                  \n add_30 (Add)                (None, 1, 1, 32)             0         ['dense_61[0][0]',            \n                                                                     'dense_61[1][0]']            \n                                                                                                  \n activation_105 (Activation  (None, 1, 1, 32)             0         ['add_30[0][0]']              \n )                                                                                                \n                                                                                                  \n multiply_60 (Multiply)      (None, 256, 256, 32)         0         ['activation_104[0][0]',      \n                                                                     'activation_105[0][0]']      \n                                                                                                  \n lambda_60 (Lambda)          (None, 256, 256, 1)          0         ['multiply_60[0][0]']         \n                                                                                                  \n lambda_61 (Lambda)          (None, 256, 256, 1)          0         ['multiply_60[0][0]']         \n                                                                                                  \n concatenate_47 (Concatenat  (None, 256, 256, 2)          0         ['lambda_60[0][0]',           \n e)                                                                  'lambda_61[0][0]']           \n                                                                                                  \n conv2d_105 (Conv2D)         (None, 256, 256, 1)          98        ['concatenate_47[0][0]']      \n                                                                                                  \n multiply_61 (Multiply)      (None, 256, 256, 32)         0         ['multiply_60[0][0]',         \n                                                                     'conv2d_105[0][0]']          \n                                                                                                  \n average_pooling2d_15 (Aver  (None, 128, 128, 32)         0         ['multiply_61[0][0]']         \n agePooling2D)                                                                                    \n                                                                                                  \n conv2d_106 (Conv2D)         (None, 128, 128, 64)         18496     ['average_pooling2d_15[0][0]']\n                                                                                                  \n batch_normalization_73 (Ba  (None, 128, 128, 64)         256       ['conv2d_106[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_106 (Activation  (None, 128, 128, 64)         0         ['batch_normalization_73[0][0]\n )                                                                  ']                            \n                                                                                                  \n dropout_3 (Dropout)         (None, 128, 128, 64)         0         ['activation_106[0][0]']      \n                                                                                                  \n conv2d_107 (Conv2D)         (None, 128, 128, 64)         36928     ['dropout_3[0][0]']           \n                                                                                                  \n batch_normalization_74 (Ba  (None, 128, 128, 64)         256       ['conv2d_107[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_107 (Activation  (None, 128, 128, 64)         0         ['batch_normalization_74[0][0]\n )                                                                  ']                            \n                                                                                                  \n global_average_pooling2d_3  (None, 64)                   0         ['activation_107[0][0]']      \n 1 (GlobalAveragePooling2D)                                                                       \n                                                                                                  \n global_max_pooling2d_31 (G  (None, 64)                   0         ['activation_107[0][0]']      \n lobalMaxPooling2D)                                                                               \n                                                                                                  \n reshape_62 (Reshape)        (None, 1, 1, 64)             0         ['global_average_pooling2d_31[\n                                                                    0][0]']                       \n                                                                                                  \n reshape_63 (Reshape)        (None, 1, 1, 64)             0         ['global_max_pooling2d_31[0][0\n                                                                    ]']                           \n                                                                                                  \n dense_62 (Dense)            (None, 1, 1, 8)              520       ['reshape_62[0][0]',          \n                                                                     'reshape_63[0][0]']          \n                                                                                                  \n dense_63 (Dense)            (None, 1, 1, 64)             576       ['dense_62[0][0]',            \n                                                                     'dense_62[1][0]']            \n                                                                                                  \n add_31 (Add)                (None, 1, 1, 64)             0         ['dense_63[0][0]',            \n                                                                     'dense_63[1][0]']            \n                                                                                                  \n activation_108 (Activation  (None, 1, 1, 64)             0         ['add_31[0][0]']              \n )                                                                                                \n                                                                                                  \n multiply_62 (Multiply)      (None, 128, 128, 64)         0         ['activation_107[0][0]',      \n                                                                     'activation_108[0][0]']      \n                                                                                                  \n lambda_62 (Lambda)          (None, 128, 128, 1)          0         ['multiply_62[0][0]']         \n                                                                                                  \n lambda_63 (Lambda)          (None, 128, 128, 1)          0         ['multiply_62[0][0]']         \n                                                                                                  \n concatenate_48 (Concatenat  (None, 128, 128, 2)          0         ['lambda_62[0][0]',           \n e)                                                                  'lambda_63[0][0]']           \n                                                                                                  \n conv2d_108 (Conv2D)         (None, 128, 128, 1)          98        ['concatenate_48[0][0]']      \n                                                                                                  \n multiply_63 (Multiply)      (None, 128, 128, 64)         0         ['multiply_62[0][0]',         \n                                                                     'conv2d_108[0][0]']          \n                                                                                                  \n average_pooling2d_16 (Aver  (None, 64, 64, 64)           0         ['multiply_63[0][0]']         \n agePooling2D)                                                                                    \n                                                                                                  \n conv2d_109 (Conv2D)         (None, 64, 64, 128)          73856     ['average_pooling2d_16[0][0]']\n                                                                                                  \n batch_normalization_75 (Ba  (None, 64, 64, 128)          512       ['conv2d_109[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_109 (Activation  (None, 64, 64, 128)          0         ['batch_normalization_75[0][0]\n )                                                                  ']                            \n                                                                                                  \n conv2d_110 (Conv2D)         (None, 64, 64, 128)          147584    ['activation_109[0][0]']      \n                                                                                                  \n batch_normalization_76 (Ba  (None, 64, 64, 128)          512       ['conv2d_110[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_110 (Activation  (None, 64, 64, 128)          0         ['batch_normalization_76[0][0]\n )                                                                  ']                            \n                                                                                                  \n global_average_pooling2d_3  (None, 128)                  0         ['activation_110[0][0]']      \n 2 (GlobalAveragePooling2D)                                                                       \n                                                                                                  \n global_max_pooling2d_32 (G  (None, 128)                  0         ['activation_110[0][0]']      \n lobalMaxPooling2D)                                                                               \n                                                                                                  \n reshape_64 (Reshape)        (None, 1, 1, 128)            0         ['global_average_pooling2d_32[\n                                                                    0][0]']                       \n                                                                                                  \n reshape_65 (Reshape)        (None, 1, 1, 128)            0         ['global_max_pooling2d_32[0][0\n                                                                    ]']                           \n                                                                                                  \n dense_64 (Dense)            (None, 1, 1, 16)             2064      ['reshape_64[0][0]',          \n                                                                     'reshape_65[0][0]']          \n                                                                                                  \n dense_65 (Dense)            (None, 1, 1, 128)            2176      ['dense_64[0][0]',            \n                                                                     'dense_64[1][0]']            \n                                                                                                  \n add_32 (Add)                (None, 1, 1, 128)            0         ['dense_65[0][0]',            \n                                                                     'dense_65[1][0]']            \n                                                                                                  \n activation_111 (Activation  (None, 1, 1, 128)            0         ['add_32[0][0]']              \n )                                                                                                \n                                                                                                  \n multiply_64 (Multiply)      (None, 64, 64, 128)          0         ['activation_110[0][0]',      \n                                                                     'activation_111[0][0]']      \n                                                                                                  \n lambda_64 (Lambda)          (None, 64, 64, 1)            0         ['multiply_64[0][0]']         \n                                                                                                  \n lambda_65 (Lambda)          (None, 64, 64, 1)            0         ['multiply_64[0][0]']         \n                                                                                                  \n concatenate_49 (Concatenat  (None, 64, 64, 2)            0         ['lambda_64[0][0]',           \n e)                                                                  'lambda_65[0][0]']           \n                                                                                                  \n conv2d_111 (Conv2D)         (None, 64, 64, 1)            98        ['concatenate_49[0][0]']      \n                                                                                                  \n multiply_65 (Multiply)      (None, 64, 64, 128)          0         ['multiply_64[0][0]',         \n                                                                     'conv2d_111[0][0]']          \n                                                                                                  \n average_pooling2d_17 (Aver  (None, 32, 32, 128)          0         ['multiply_65[0][0]']         \n agePooling2D)                                                                                    \n                                                                                                  \n conv2d_112 (Conv2D)         (None, 32, 32, 256)          295168    ['average_pooling2d_17[0][0]']\n                                                                                                  \n batch_normalization_77 (Ba  (None, 32, 32, 256)          1024      ['conv2d_112[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_112 (Activation  (None, 32, 32, 256)          0         ['batch_normalization_77[0][0]\n )                                                                  ']                            \n                                                                                                  \n conv2d_113 (Conv2D)         (None, 32, 32, 256)          590080    ['activation_112[0][0]']      \n                                                                                                  \n batch_normalization_78 (Ba  (None, 32, 32, 256)          1024      ['conv2d_113[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_113 (Activation  (None, 32, 32, 256)          0         ['batch_normalization_78[0][0]\n )                                                                  ']                            \n                                                                                                  \n global_average_pooling2d_3  (None, 256)                  0         ['activation_113[0][0]']      \n 3 (GlobalAveragePooling2D)                                                                       \n                                                                                                  \n global_max_pooling2d_33 (G  (None, 256)                  0         ['activation_113[0][0]']      \n lobalMaxPooling2D)                                                                               \n                                                                                                  \n reshape_66 (Reshape)        (None, 1, 1, 256)            0         ['global_average_pooling2d_33[\n                                                                    0][0]']                       \n                                                                                                  \n reshape_67 (Reshape)        (None, 1, 1, 256)            0         ['global_max_pooling2d_33[0][0\n                                                                    ]']                           \n                                                                                                  \n dense_66 (Dense)            (None, 1, 1, 32)             8224      ['reshape_66[0][0]',          \n                                                                     'reshape_67[0][0]']          \n                                                                                                  \n dense_67 (Dense)            (None, 1, 1, 256)            8448      ['dense_66[0][0]',            \n                                                                     'dense_66[1][0]']            \n                                                                                                  \n add_33 (Add)                (None, 1, 1, 256)            0         ['dense_67[0][0]',            \n                                                                     'dense_67[1][0]']            \n                                                                                                  \n activation_114 (Activation  (None, 1, 1, 256)            0         ['add_33[0][0]']              \n )                                                                                                \n                                                                                                  \n multiply_66 (Multiply)      (None, 32, 32, 256)          0         ['activation_113[0][0]',      \n                                                                     'activation_114[0][0]']      \n                                                                                                  \n lambda_66 (Lambda)          (None, 32, 32, 1)            0         ['multiply_66[0][0]']         \n                                                                                                  \n lambda_67 (Lambda)          (None, 32, 32, 1)            0         ['multiply_66[0][0]']         \n                                                                                                  \n concatenate_50 (Concatenat  (None, 32, 32, 2)            0         ['lambda_66[0][0]',           \n e)                                                                  'lambda_67[0][0]']           \n                                                                                                  \n conv2d_114 (Conv2D)         (None, 32, 32, 1)            98        ['concatenate_50[0][0]']      \n                                                                                                  \n multiply_67 (Multiply)      (None, 32, 32, 256)          0         ['multiply_66[0][0]',         \n                                                                     'conv2d_114[0][0]']          \n                                                                                                  \n average_pooling2d_18 (Aver  (None, 16, 16, 256)          0         ['multiply_67[0][0]']         \n agePooling2D)                                                                                    \n                                                                                                  \n conv2d_115 (Conv2D)         (None, 16, 16, 512)          1180160   ['average_pooling2d_18[0][0]']\n                                                                                                  \n batch_normalization_79 (Ba  (None, 16, 16, 512)          2048      ['conv2d_115[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_115 (Activation  (None, 16, 16, 512)          0         ['batch_normalization_79[0][0]\n )                                                                  ']                            \n                                                                                                  \n conv2d_116 (Conv2D)         (None, 16, 16, 512)          2359808   ['activation_115[0][0]']      \n                                                                                                  \n batch_normalization_80 (Ba  (None, 16, 16, 512)          2048      ['conv2d_116[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_116 (Activation  (None, 16, 16, 512)          0         ['batch_normalization_80[0][0]\n )                                                                  ']                            \n                                                                                                  \n global_average_pooling2d_3  (None, 512)                  0         ['activation_116[0][0]']      \n 4 (GlobalAveragePooling2D)                                                                       \n                                                                                                  \n global_max_pooling2d_34 (G  (None, 512)                  0         ['activation_116[0][0]']      \n lobalMaxPooling2D)                                                                               \n                                                                                                  \n reshape_68 (Reshape)        (None, 1, 1, 512)            0         ['global_average_pooling2d_34[\n                                                                    0][0]']                       \n                                                                                                  \n reshape_69 (Reshape)        (None, 1, 1, 512)            0         ['global_max_pooling2d_34[0][0\n                                                                    ]']                           \n                                                                                                  \n dense_68 (Dense)            (None, 1, 1, 64)             32832     ['reshape_68[0][0]',          \n                                                                     'reshape_69[0][0]']          \n                                                                                                  \n dense_69 (Dense)            (None, 1, 1, 512)            33280     ['dense_68[0][0]',            \n                                                                     'dense_68[1][0]']            \n                                                                                                  \n add_34 (Add)                (None, 1, 1, 512)            0         ['dense_69[0][0]',            \n                                                                     'dense_69[1][0]']            \n                                                                                                  \n activation_117 (Activation  (None, 1, 1, 512)            0         ['add_34[0][0]']              \n )                                                                                                \n                                                                                                  \n multiply_68 (Multiply)      (None, 16, 16, 512)          0         ['activation_116[0][0]',      \n                                                                     'activation_117[0][0]']      \n                                                                                                  \n lambda_68 (Lambda)          (None, 16, 16, 1)            0         ['multiply_68[0][0]']         \n                                                                                                  \n lambda_69 (Lambda)          (None, 16, 16, 1)            0         ['multiply_68[0][0]']         \n                                                                                                  \n concatenate_51 (Concatenat  (None, 16, 16, 2)            0         ['lambda_68[0][0]',           \n e)                                                                  'lambda_69[0][0]']           \n                                                                                                  \n conv2d_117 (Conv2D)         (None, 16, 16, 1)            98        ['concatenate_51[0][0]']      \n                                                                                                  \n multiply_69 (Multiply)      (None, 16, 16, 512)          0         ['multiply_68[0][0]',         \n                                                                     'conv2d_117[0][0]']          \n                                                                                                  \n average_pooling2d_19 (Aver  (None, 8, 8, 512)            0         ['multiply_69[0][0]']         \n agePooling2D)                                                                                    \n                                                                                                  \n conv2d_118 (Conv2D)         (None, 8, 8, 1024)           4719616   ['average_pooling2d_19[0][0]']\n                                                                                                  \n batch_normalization_81 (Ba  (None, 8, 8, 1024)           4096      ['conv2d_118[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_118 (Activation  (None, 8, 8, 1024)           0         ['batch_normalization_81[0][0]\n )                                                                  ']                            \n                                                                                                  \n conv2d_119 (Conv2D)         (None, 8, 8, 512)            4719104   ['activation_118[0][0]']      \n                                                                                                  \n batch_normalization_82 (Ba  (None, 8, 8, 512)            2048      ['conv2d_119[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_119 (Activation  (None, 8, 8, 512)            0         ['batch_normalization_82[0][0]\n )                                                                  ']                            \n                                                                                                  \n global_average_pooling2d_3  (None, 512)                  0         ['activation_119[0][0]']      \n 5 (GlobalAveragePooling2D)                                                                       \n                                                                                                  \n global_max_pooling2d_35 (G  (None, 512)                  0         ['activation_119[0][0]']      \n lobalMaxPooling2D)                                                                               \n                                                                                                  \n reshape_70 (Reshape)        (None, 1, 1, 512)            0         ['global_average_pooling2d_35[\n                                                                    0][0]']                       \n                                                                                                  \n reshape_71 (Reshape)        (None, 1, 1, 512)            0         ['global_max_pooling2d_35[0][0\n                                                                    ]']                           \n                                                                                                  \n dense_70 (Dense)            (None, 1, 1, 64)             32832     ['reshape_70[0][0]',          \n                                                                     'reshape_71[0][0]']          \n                                                                                                  \n dense_71 (Dense)            (None, 1, 1, 512)            33280     ['dense_70[0][0]',            \n                                                                     'dense_70[1][0]']            \n                                                                                                  \n add_35 (Add)                (None, 1, 1, 512)            0         ['dense_71[0][0]',            \n                                                                     'dense_71[1][0]']            \n                                                                                                  \n activation_120 (Activation  (None, 1, 1, 512)            0         ['add_35[0][0]']              \n )                                                                                                \n                                                                                                  \n multiply_70 (Multiply)      (None, 8, 8, 512)            0         ['activation_119[0][0]',      \n                                                                     'activation_120[0][0]']      \n                                                                                                  \n lambda_70 (Lambda)          (None, 8, 8, 1)              0         ['multiply_70[0][0]']         \n                                                                                                  \n lambda_71 (Lambda)          (None, 8, 8, 1)              0         ['multiply_70[0][0]']         \n                                                                                                  \n concatenate_52 (Concatenat  (None, 8, 8, 2)              0         ['lambda_70[0][0]',           \n e)                                                                  'lambda_71[0][0]']           \n                                                                                                  \n conv2d_120 (Conv2D)         (None, 8, 8, 1)              98        ['concatenate_52[0][0]']      \n                                                                                                  \n multiply_71 (Multiply)      (None, 8, 8, 512)            0         ['multiply_70[0][0]',         \n                                                                     'conv2d_120[0][0]']          \n                                                                                                  \n up_sampling2d_13 (UpSampli  (None, 16, 16, 512)          0         ['multiply_71[0][0]']         \n ng2D)                                                                                            \n                                                                                                  \n concatenate_53 (Concatenat  (None, 16, 16, 1024)         0         ['up_sampling2d_13[0][0]',    \n e)                                                                  'multiply_69[0][0]']         \n                                                                                                  \n conv2d_121 (Conv2D)         (None, 16, 16, 512)          4719104   ['concatenate_53[0][0]']      \n                                                                                                  \n batch_normalization_83 (Ba  (None, 16, 16, 512)          2048      ['conv2d_121[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_121 (Activation  (None, 16, 16, 512)          0         ['batch_normalization_83[0][0]\n )                                                                  ']                            \n                                                                                                  \n conv2d_122 (Conv2D)         (None, 16, 16, 512)          2359808   ['activation_121[0][0]']      \n                                                                                                  \n batch_normalization_84 (Ba  (None, 16, 16, 512)          2048      ['conv2d_122[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_122 (Activation  (None, 16, 16, 512)          0         ['batch_normalization_84[0][0]\n )                                                                  ']                            \n                                                                                                  \n global_average_pooling2d_3  (None, 512)                  0         ['activation_122[0][0]']      \n 6 (GlobalAveragePooling2D)                                                                       \n                                                                                                  \n global_max_pooling2d_36 (G  (None, 512)                  0         ['activation_122[0][0]']      \n lobalMaxPooling2D)                                                                               \n                                                                                                  \n reshape_72 (Reshape)        (None, 1, 1, 512)            0         ['global_average_pooling2d_36[\n                                                                    0][0]']                       \n                                                                                                  \n reshape_73 (Reshape)        (None, 1, 1, 512)            0         ['global_max_pooling2d_36[0][0\n                                                                    ]']                           \n                                                                                                  \n dense_72 (Dense)            (None, 1, 1, 64)             32832     ['reshape_72[0][0]',          \n                                                                     'reshape_73[0][0]']          \n                                                                                                  \n dense_73 (Dense)            (None, 1, 1, 512)            33280     ['dense_72[0][0]',            \n                                                                     'dense_72[1][0]']            \n                                                                                                  \n add_36 (Add)                (None, 1, 1, 512)            0         ['dense_73[0][0]',            \n                                                                     'dense_73[1][0]']            \n                                                                                                  \n activation_123 (Activation  (None, 1, 1, 512)            0         ['add_36[0][0]']              \n )                                                                                                \n                                                                                                  \n multiply_72 (Multiply)      (None, 16, 16, 512)          0         ['activation_122[0][0]',      \n                                                                     'activation_123[0][0]']      \n                                                                                                  \n lambda_72 (Lambda)          (None, 16, 16, 1)            0         ['multiply_72[0][0]']         \n                                                                                                  \n lambda_73 (Lambda)          (None, 16, 16, 1)            0         ['multiply_72[0][0]']         \n                                                                                                  \n concatenate_54 (Concatenat  (None, 16, 16, 2)            0         ['lambda_72[0][0]',           \n e)                                                                  'lambda_73[0][0]']           \n                                                                                                  \n conv2d_123 (Conv2D)         (None, 16, 16, 1)            98        ['concatenate_54[0][0]']      \n                                                                                                  \n multiply_73 (Multiply)      (None, 16, 16, 512)          0         ['multiply_72[0][0]',         \n                                                                     'conv2d_123[0][0]']          \n                                                                                                  \n up_sampling2d_14 (UpSampli  (None, 32, 32, 512)          0         ['multiply_73[0][0]']         \n ng2D)                                                                                            \n                                                                                                  \n concatenate_55 (Concatenat  (None, 32, 32, 768)          0         ['up_sampling2d_14[0][0]',    \n e)                                                                  'multiply_67[0][0]']         \n                                                                                                  \n conv2d_124 (Conv2D)         (None, 32, 32, 256)          1769728   ['concatenate_55[0][0]']      \n                                                                                                  \n batch_normalization_85 (Ba  (None, 32, 32, 256)          1024      ['conv2d_124[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_124 (Activation  (None, 32, 32, 256)          0         ['batch_normalization_85[0][0]\n )                                                                  ']                            \n                                                                                                  \n conv2d_125 (Conv2D)         (None, 32, 32, 256)          590080    ['activation_124[0][0]']      \n                                                                                                  \n batch_normalization_86 (Ba  (None, 32, 32, 256)          1024      ['conv2d_125[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_125 (Activation  (None, 32, 32, 256)          0         ['batch_normalization_86[0][0]\n )                                                                  ']                            \n                                                                                                  \n global_average_pooling2d_3  (None, 256)                  0         ['activation_125[0][0]']      \n 7 (GlobalAveragePooling2D)                                                                       \n                                                                                                  \n global_max_pooling2d_37 (G  (None, 256)                  0         ['activation_125[0][0]']      \n lobalMaxPooling2D)                                                                               \n                                                                                                  \n reshape_74 (Reshape)        (None, 1, 1, 256)            0         ['global_average_pooling2d_37[\n                                                                    0][0]']                       \n                                                                                                  \n reshape_75 (Reshape)        (None, 1, 1, 256)            0         ['global_max_pooling2d_37[0][0\n                                                                    ]']                           \n                                                                                                  \n dense_74 (Dense)            (None, 1, 1, 32)             8224      ['reshape_74[0][0]',          \n                                                                     'reshape_75[0][0]']          \n                                                                                                  \n dense_75 (Dense)            (None, 1, 1, 256)            8448      ['dense_74[0][0]',            \n                                                                     'dense_74[1][0]']            \n                                                                                                  \n add_37 (Add)                (None, 1, 1, 256)            0         ['dense_75[0][0]',            \n                                                                     'dense_75[1][0]']            \n                                                                                                  \n activation_126 (Activation  (None, 1, 1, 256)            0         ['add_37[0][0]']              \n )                                                                                                \n                                                                                                  \n multiply_74 (Multiply)      (None, 32, 32, 256)          0         ['activation_125[0][0]',      \n                                                                     'activation_126[0][0]']      \n                                                                                                  \n lambda_74 (Lambda)          (None, 32, 32, 1)            0         ['multiply_74[0][0]']         \n                                                                                                  \n lambda_75 (Lambda)          (None, 32, 32, 1)            0         ['multiply_74[0][0]']         \n                                                                                                  \n concatenate_56 (Concatenat  (None, 32, 32, 2)            0         ['lambda_74[0][0]',           \n e)                                                                  'lambda_75[0][0]']           \n                                                                                                  \n conv2d_126 (Conv2D)         (None, 32, 32, 1)            98        ['concatenate_56[0][0]']      \n                                                                                                  \n multiply_75 (Multiply)      (None, 32, 32, 256)          0         ['multiply_74[0][0]',         \n                                                                     'conv2d_126[0][0]']          \n                                                                                                  \n up_sampling2d_15 (UpSampli  (None, 64, 64, 256)          0         ['multiply_75[0][0]']         \n ng2D)                                                                                            \n                                                                                                  \n concatenate_57 (Concatenat  (None, 64, 64, 384)          0         ['up_sampling2d_15[0][0]',    \n e)                                                                  'multiply_65[0][0]']         \n                                                                                                  \n conv2d_127 (Conv2D)         (None, 64, 64, 128)          442496    ['concatenate_57[0][0]']      \n                                                                                                  \n batch_normalization_87 (Ba  (None, 64, 64, 128)          512       ['conv2d_127[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_127 (Activation  (None, 64, 64, 128)          0         ['batch_normalization_87[0][0]\n )                                                                  ']                            \n                                                                                                  \n conv2d_128 (Conv2D)         (None, 64, 64, 128)          147584    ['activation_127[0][0]']      \n                                                                                                  \n batch_normalization_88 (Ba  (None, 64, 64, 128)          512       ['conv2d_128[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_128 (Activation  (None, 64, 64, 128)          0         ['batch_normalization_88[0][0]\n )                                                                  ']                            \n                                                                                                  \n up_sampling2d_16 (UpSampli  (None, 128, 128, 128)        0         ['activation_128[0][0]']      \n ng2D)                                                                                            \n                                                                                                  \n concatenate_59 (Concatenat  (None, 128, 128, 192)        0         ['up_sampling2d_16[0][0]',    \n e)                                                                  'multiply_63[0][0]']         \n                                                                                                  \n conv2d_130 (Conv2D)         (None, 128, 128, 64)         110656    ['concatenate_59[0][0]']      \n                                                                                                  \n batch_normalization_89 (Ba  (None, 128, 128, 64)         256       ['conv2d_130[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_130 (Activation  (None, 128, 128, 64)         0         ['batch_normalization_89[0][0]\n )                                                                  ']                            \n                                                                                                  \n conv2d_131 (Conv2D)         (None, 128, 128, 64)         36928     ['activation_130[0][0]']      \n                                                                                                  \n batch_normalization_90 (Ba  (None, 128, 128, 64)         256       ['conv2d_131[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_131 (Activation  (None, 128, 128, 64)         0         ['batch_normalization_90[0][0]\n )                                                                  ']                            \n                                                                                                  \n global_average_pooling2d_3  (None, 64)                   0         ['activation_131[0][0]']      \n 9 (GlobalAveragePooling2D)                                                                       \n                                                                                                  \n global_max_pooling2d_39 (G  (None, 64)                   0         ['activation_131[0][0]']      \n lobalMaxPooling2D)                                                                               \n                                                                                                  \n reshape_78 (Reshape)        (None, 1, 1, 64)             0         ['global_average_pooling2d_39[\n                                                                    0][0]']                       \n                                                                                                  \n reshape_79 (Reshape)        (None, 1, 1, 64)             0         ['global_max_pooling2d_39[0][0\n                                                                    ]']                           \n                                                                                                  \n dense_78 (Dense)            (None, 1, 1, 8)              520       ['reshape_78[0][0]',          \n                                                                     'reshape_79[0][0]']          \n                                                                                                  \n dense_79 (Dense)            (None, 1, 1, 64)             576       ['dense_78[0][0]',            \n                                                                     'dense_78[1][0]']            \n                                                                                                  \n add_39 (Add)                (None, 1, 1, 64)             0         ['dense_79[0][0]',            \n                                                                     'dense_79[1][0]']            \n                                                                                                  \n activation_132 (Activation  (None, 1, 1, 64)             0         ['add_39[0][0]']              \n )                                                                                                \n                                                                                                  \n multiply_78 (Multiply)      (None, 128, 128, 64)         0         ['activation_131[0][0]',      \n                                                                     'activation_132[0][0]']      \n                                                                                                  \n lambda_78 (Lambda)          (None, 128, 128, 1)          0         ['multiply_78[0][0]']         \n                                                                                                  \n lambda_79 (Lambda)          (None, 128, 128, 1)          0         ['multiply_78[0][0]']         \n                                                                                                  \n concatenate_60 (Concatenat  (None, 128, 128, 2)          0         ['lambda_78[0][0]',           \n e)                                                                  'lambda_79[0][0]']           \n                                                                                                  \n conv2d_132 (Conv2D)         (None, 128, 128, 1)          98        ['concatenate_60[0][0]']      \n                                                                                                  \n multiply_79 (Multiply)      (None, 128, 128, 64)         0         ['multiply_78[0][0]',         \n                                                                     'conv2d_132[0][0]']          \n                                                                                                  \n up_sampling2d_17 (UpSampli  (None, 256, 256, 64)         0         ['multiply_79[0][0]']         \n ng2D)                                                                                            \n                                                                                                  \n concatenate_61 (Concatenat  (None, 256, 256, 96)         0         ['up_sampling2d_17[0][0]',    \n e)                                                                  'multiply_61[0][0]']         \n                                                                                                  \n conv2d_133 (Conv2D)         (None, 256, 256, 32)         27680     ['concatenate_61[0][0]']      \n                                                                                                  \n batch_normalization_91 (Ba  (None, 256, 256, 32)         128       ['conv2d_133[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_133 (Activation  (None, 256, 256, 32)         0         ['batch_normalization_91[0][0]\n )                                                                  ']                            \n                                                                                                  \n conv2d_134 (Conv2D)         (None, 256, 256, 32)         9248      ['activation_133[0][0]']      \n                                                                                                  \n batch_normalization_92 (Ba  (None, 256, 256, 32)         128       ['conv2d_134[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_134 (Activation  (None, 256, 256, 32)         0         ['batch_normalization_92[0][0]\n )                                                                  ']                            \n                                                                                                  \n global_average_pooling2d_4  (None, 32)                   0         ['activation_134[0][0]']      \n 0 (GlobalAveragePooling2D)                                                                       \n                                                                                                  \n global_max_pooling2d_40 (G  (None, 32)                   0         ['activation_134[0][0]']      \n lobalMaxPooling2D)                                                                               \n                                                                                                  \n reshape_80 (Reshape)        (None, 1, 1, 32)             0         ['global_average_pooling2d_40[\n                                                                    0][0]']                       \n                                                                                                  \n reshape_81 (Reshape)        (None, 1, 1, 32)             0         ['global_max_pooling2d_40[0][0\n                                                                    ]']                           \n                                                                                                  \n dense_80 (Dense)            (None, 1, 1, 4)              132       ['reshape_80[0][0]',          \n                                                                     'reshape_81[0][0]']          \n                                                                                                  \n dense_81 (Dense)            (None, 1, 1, 32)             160       ['dense_80[0][0]',            \n                                                                     'dense_80[1][0]']            \n                                                                                                  \n add_40 (Add)                (None, 1, 1, 32)             0         ['dense_81[0][0]',            \n                                                                     'dense_81[1][0]']            \n                                                                                                  \n activation_135 (Activation  (None, 1, 1, 32)             0         ['add_40[0][0]']              \n )                                                                                                \n                                                                                                  \n multiply_80 (Multiply)      (None, 256, 256, 32)         0         ['activation_134[0][0]',      \n                                                                     'activation_135[0][0]']      \n                                                                                                  \n lambda_80 (Lambda)          (None, 256, 256, 1)          0         ['multiply_80[0][0]']         \n                                                                                                  \n lambda_81 (Lambda)          (None, 256, 256, 1)          0         ['multiply_80[0][0]']         \n                                                                                                  \n concatenate_62 (Concatenat  (None, 256, 256, 2)          0         ['lambda_80[0][0]',           \n e)                                                                  'lambda_81[0][0]']           \n                                                                                                  \n conv2d_135 (Conv2D)         (None, 256, 256, 1)          98        ['concatenate_62[0][0]']      \n                                                                                                  \n multiply_81 (Multiply)      (None, 256, 256, 32)         0         ['multiply_80[0][0]',         \n                                                                     'conv2d_135[0][0]']          \n                                                                                                  \n conv2d_136 (Conv2D)         (None, 256, 256, 1)          289       ['multiply_81[0][0]']         \n                                                                                                  \n activation_136 (Activation  (None, 256, 256, 1)          0         ['conv2d_136[0][0]']          \n )                                                                                                \n                                                                                                  \n concatenate_63 (Concatenat  (None, 256, 256, 193)        0         ['concatenate_46[0][0]',      \n e)                                                                  'activation_136[0][0]']      \n                                                                                                  \n conv2d_137 (Conv2D)         (None, 256, 256, 32)         55616     ['concatenate_63[0][0]']      \n                                                                                                  \n batch_normalization_93 (Ba  (None, 256, 256, 32)         128       ['conv2d_137[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_137 (Activation  (None, 256, 256, 32)         0         ['batch_normalization_93[0][0]\n )                                                                  ']                            \n                                                                                                  \n conv2d_138 (Conv2D)         (None, 256, 256, 32)         9248      ['activation_137[0][0]']      \n                                                                                                  \n batch_normalization_94 (Ba  (None, 256, 256, 32)         128       ['conv2d_138[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_138 (Activation  (None, 256, 256, 32)         0         ['batch_normalization_94[0][0]\n )                                                                  ']                            \n                                                                                                  \n global_average_pooling2d_4  (None, 32)                   0         ['activation_138[0][0]']      \n 1 (GlobalAveragePooling2D)                                                                       \n                                                                                                  \n global_max_pooling2d_41 (G  (None, 32)                   0         ['activation_138[0][0]']      \n lobalMaxPooling2D)                                                                               \n                                                                                                  \n reshape_82 (Reshape)        (None, 1, 1, 32)             0         ['global_average_pooling2d_41[\n                                                                    0][0]']                       \n                                                                                                  \n reshape_83 (Reshape)        (None, 1, 1, 32)             0         ['global_max_pooling2d_41[0][0\n                                                                    ]']                           \n                                                                                                  \n dense_82 (Dense)            (None, 1, 1, 4)              132       ['reshape_82[0][0]',          \n                                                                     'reshape_83[0][0]']          \n                                                                                                  \n dense_83 (Dense)            (None, 1, 1, 32)             160       ['dense_82[0][0]',            \n                                                                     'dense_82[1][0]']            \n                                                                                                  \n add_41 (Add)                (None, 1, 1, 32)             0         ['dense_83[0][0]',            \n                                                                     'dense_83[1][0]']            \n                                                                                                  \n activation_139 (Activation  (None, 1, 1, 32)             0         ['add_41[0][0]']              \n )                                                                                                \n                                                                                                  \n multiply_82 (Multiply)      (None, 256, 256, 32)         0         ['activation_138[0][0]',      \n                                                                     'activation_139[0][0]']      \n                                                                                                  \n lambda_82 (Lambda)          (None, 256, 256, 1)          0         ['multiply_82[0][0]']         \n                                                                                                  \n lambda_83 (Lambda)          (None, 256, 256, 1)          0         ['multiply_82[0][0]']         \n                                                                                                  \n concatenate_64 (Concatenat  (None, 256, 256, 2)          0         ['lambda_82[0][0]',           \n e)                                                                  'lambda_83[0][0]']           \n                                                                                                  \n conv2d_139 (Conv2D)         (None, 256, 256, 1)          98        ['concatenate_64[0][0]']      \n                                                                                                  \n multiply_83 (Multiply)      (None, 256, 256, 32)         0         ['multiply_82[0][0]',         \n                                                                     'conv2d_139[0][0]']          \n                                                                                                  \n average_pooling2d_20 (Aver  (None, 128, 128, 32)         0         ['multiply_83[0][0]']         \n agePooling2D)                                                                                    \n                                                                                                  \n conv2d_140 (Conv2D)         (None, 128, 128, 64)         18496     ['average_pooling2d_20[0][0]']\n                                                                                                  \n batch_normalization_95 (Ba  (None, 128, 128, 64)         256       ['conv2d_140[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_140 (Activation  (None, 128, 128, 64)         0         ['batch_normalization_95[0][0]\n )                                                                  ']                            \n                                                                                                  \n dropout_4 (Dropout)         (None, 128, 128, 64)         0         ['activation_140[0][0]']      \n                                                                                                  \n conv2d_141 (Conv2D)         (None, 128, 128, 64)         36928     ['dropout_4[0][0]']           \n                                                                                                  \n batch_normalization_96 (Ba  (None, 128, 128, 64)         256       ['conv2d_141[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_141 (Activation  (None, 128, 128, 64)         0         ['batch_normalization_96[0][0]\n )                                                                  ']                            \n                                                                                                  \n global_average_pooling2d_4  (None, 64)                   0         ['activation_141[0][0]']      \n 2 (GlobalAveragePooling2D)                                                                       \n                                                                                                  \n global_max_pooling2d_42 (G  (None, 64)                   0         ['activation_141[0][0]']      \n lobalMaxPooling2D)                                                                               \n                                                                                                  \n reshape_84 (Reshape)        (None, 1, 1, 64)             0         ['global_average_pooling2d_42[\n                                                                    0][0]']                       \n                                                                                                  \n reshape_85 (Reshape)        (None, 1, 1, 64)             0         ['global_max_pooling2d_42[0][0\n                                                                    ]']                           \n                                                                                                  \n dense_84 (Dense)            (None, 1, 1, 8)              520       ['reshape_84[0][0]',          \n                                                                     'reshape_85[0][0]']          \n                                                                                                  \n dense_85 (Dense)            (None, 1, 1, 64)             576       ['dense_84[0][0]',            \n                                                                     'dense_84[1][0]']            \n                                                                                                  \n add_42 (Add)                (None, 1, 1, 64)             0         ['dense_85[0][0]',            \n                                                                     'dense_85[1][0]']            \n                                                                                                  \n activation_142 (Activation  (None, 1, 1, 64)             0         ['add_42[0][0]']              \n )                                                                                                \n                                                                                                  \n multiply_84 (Multiply)      (None, 128, 128, 64)         0         ['activation_141[0][0]',      \n                                                                     'activation_142[0][0]']      \n                                                                                                  \n lambda_84 (Lambda)          (None, 128, 128, 1)          0         ['multiply_84[0][0]']         \n                                                                                                  \n lambda_85 (Lambda)          (None, 128, 128, 1)          0         ['multiply_84[0][0]']         \n                                                                                                  \n concatenate_65 (Concatenat  (None, 128, 128, 2)          0         ['lambda_84[0][0]',           \n e)                                                                  'lambda_85[0][0]']           \n                                                                                                  \n conv2d_142 (Conv2D)         (None, 128, 128, 1)          98        ['concatenate_65[0][0]']      \n                                                                                                  \n multiply_85 (Multiply)      (None, 128, 128, 64)         0         ['multiply_84[0][0]',         \n                                                                     'conv2d_142[0][0]']          \n                                                                                                  \n average_pooling2d_21 (Aver  (None, 64, 64, 64)           0         ['multiply_85[0][0]']         \n agePooling2D)                                                                                    \n                                                                                                  \n conv2d_143 (Conv2D)         (None, 64, 64, 128)          73856     ['average_pooling2d_21[0][0]']\n                                                                                                  \n batch_normalization_97 (Ba  (None, 64, 64, 128)          512       ['conv2d_143[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_143 (Activation  (None, 64, 64, 128)          0         ['batch_normalization_97[0][0]\n )                                                                  ']                            \n                                                                                                  \n conv2d_144 (Conv2D)         (None, 64, 64, 128)          147584    ['activation_143[0][0]']      \n                                                                                                  \n batch_normalization_98 (Ba  (None, 64, 64, 128)          512       ['conv2d_144[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_144 (Activation  (None, 64, 64, 128)          0         ['batch_normalization_98[0][0]\n )                                                                  ']                            \n                                                                                                  \n global_average_pooling2d_4  (None, 128)                  0         ['activation_144[0][0]']      \n 3 (GlobalAveragePooling2D)                                                                       \n                                                                                                  \n global_max_pooling2d_43 (G  (None, 128)                  0         ['activation_144[0][0]']      \n lobalMaxPooling2D)                                                                               \n                                                                                                  \n reshape_86 (Reshape)        (None, 1, 1, 128)            0         ['global_average_pooling2d_43[\n                                                                    0][0]']                       \n                                                                                                  \n reshape_87 (Reshape)        (None, 1, 1, 128)            0         ['global_max_pooling2d_43[0][0\n                                                                    ]']                           \n                                                                                                  \n dense_86 (Dense)            (None, 1, 1, 16)             2064      ['reshape_86[0][0]',          \n                                                                     'reshape_87[0][0]']          \n                                                                                                  \n dense_87 (Dense)            (None, 1, 1, 128)            2176      ['dense_86[0][0]',            \n                                                                     'dense_86[1][0]']            \n                                                                                                  \n add_43 (Add)                (None, 1, 1, 128)            0         ['dense_87[0][0]',            \n                                                                     'dense_87[1][0]']            \n                                                                                                  \n activation_145 (Activation  (None, 1, 1, 128)            0         ['add_43[0][0]']              \n )                                                                                                \n                                                                                                  \n multiply_86 (Multiply)      (None, 64, 64, 128)          0         ['activation_144[0][0]',      \n                                                                     'activation_145[0][0]']      \n                                                                                                  \n lambda_86 (Lambda)          (None, 64, 64, 1)            0         ['multiply_86[0][0]']         \n                                                                                                  \n lambda_87 (Lambda)          (None, 64, 64, 1)            0         ['multiply_86[0][0]']         \n                                                                                                  \n concatenate_66 (Concatenat  (None, 64, 64, 2)            0         ['lambda_86[0][0]',           \n e)                                                                  'lambda_87[0][0]']           \n                                                                                                  \n conv2d_145 (Conv2D)         (None, 64, 64, 1)            98        ['concatenate_66[0][0]']      \n                                                                                                  \n multiply_87 (Multiply)      (None, 64, 64, 128)          0         ['multiply_86[0][0]',         \n                                                                     'conv2d_145[0][0]']          \n                                                                                                  \n average_pooling2d_22 (Aver  (None, 32, 32, 128)          0         ['multiply_87[0][0]']         \n agePooling2D)                                                                                    \n                                                                                                  \n conv2d_146 (Conv2D)         (None, 32, 32, 256)          295168    ['average_pooling2d_22[0][0]']\n                                                                                                  \n batch_normalization_99 (Ba  (None, 32, 32, 256)          1024      ['conv2d_146[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n activation_146 (Activation  (None, 32, 32, 256)          0         ['batch_normalization_99[0][0]\n )                                                                  ']                            \n                                                                                                  \n conv2d_147 (Conv2D)         (None, 32, 32, 256)          590080    ['activation_146[0][0]']      \n                                                                                                  \n batch_normalization_100 (B  (None, 32, 32, 256)          1024      ['conv2d_147[0][0]']          \n atchNormalization)                                                                               \n                                                                                                  \n activation_147 (Activation  (None, 32, 32, 256)          0         ['batch_normalization_100[0][0\n )                                                                  ]']                           \n                                                                                                  \n global_average_pooling2d_4  (None, 256)                  0         ['activation_147[0][0]']      \n 4 (GlobalAveragePooling2D)                                                                       \n                                                                                                  \n global_max_pooling2d_44 (G  (None, 256)                  0         ['activation_147[0][0]']      \n lobalMaxPooling2D)                                                                               \n                                                                                                  \n reshape_88 (Reshape)        (None, 1, 1, 256)            0         ['global_average_pooling2d_44[\n                                                                    0][0]']                       \n                                                                                                  \n reshape_89 (Reshape)        (None, 1, 1, 256)            0         ['global_max_pooling2d_44[0][0\n                                                                    ]']                           \n                                                                                                  \n dense_88 (Dense)            (None, 1, 1, 32)             8224      ['reshape_88[0][0]',          \n                                                                     'reshape_89[0][0]']          \n                                                                                                  \n dense_89 (Dense)            (None, 1, 1, 256)            8448      ['dense_88[0][0]',            \n                                                                     'dense_88[1][0]']            \n                                                                                                  \n add_44 (Add)                (None, 1, 1, 256)            0         ['dense_89[0][0]',            \n                                                                     'dense_89[1][0]']            \n                                                                                                  \n activation_148 (Activation  (None, 1, 1, 256)            0         ['add_44[0][0]']              \n )                                                                                                \n                                                                                                  \n multiply_88 (Multiply)      (None, 32, 32, 256)          0         ['activation_147[0][0]',      \n                                                                     'activation_148[0][0]']      \n                                                                                                  \n lambda_88 (Lambda)          (None, 32, 32, 1)            0         ['multiply_88[0][0]']         \n                                                                                                  \n lambda_89 (Lambda)          (None, 32, 32, 1)            0         ['multiply_88[0][0]']         \n                                                                                                  \n concatenate_67 (Concatenat  (None, 32, 32, 2)            0         ['lambda_88[0][0]',           \n e)                                                                  'lambda_89[0][0]']           \n                                                                                                  \n conv2d_148 (Conv2D)         (None, 32, 32, 1)            98        ['concatenate_67[0][0]']      \n                                                                                                  \n multiply_89 (Multiply)      (None, 32, 32, 256)          0         ['multiply_88[0][0]',         \n                                                                     'conv2d_148[0][0]']          \n                                                                                                  \n average_pooling2d_23 (Aver  (None, 16, 16, 256)          0         ['multiply_89[0][0]']         \n agePooling2D)                                                                                    \n                                                                                                  \n conv2d_149 (Conv2D)         (None, 16, 16, 512)          1180160   ['average_pooling2d_23[0][0]']\n                                                                                                  \n batch_normalization_101 (B  (None, 16, 16, 512)          2048      ['conv2d_149[0][0]']          \n atchNormalization)                                                                               \n                                                                                                  \n activation_149 (Activation  (None, 16, 16, 512)          0         ['batch_normalization_101[0][0\n )                                                                  ]']                           \n                                                                                                  \n conv2d_150 (Conv2D)         (None, 16, 16, 512)          2359808   ['activation_149[0][0]']      \n                                                                                                  \n batch_normalization_102 (B  (None, 16, 16, 512)          2048      ['conv2d_150[0][0]']          \n atchNormalization)                                                                               \n                                                                                                  \n activation_150 (Activation  (None, 16, 16, 512)          0         ['batch_normalization_102[0][0\n )                                                                  ]']                           \n                                                                                                  \n global_average_pooling2d_4  (None, 512)                  0         ['activation_150[0][0]']      \n 5 (GlobalAveragePooling2D)                                                                       \n                                                                                                  \n global_max_pooling2d_45 (G  (None, 512)                  0         ['activation_150[0][0]']      \n lobalMaxPooling2D)                                                                               \n                                                                                                  \n reshape_90 (Reshape)        (None, 1, 1, 512)            0         ['global_average_pooling2d_45[\n                                                                    0][0]']                       \n                                                                                                  \n reshape_91 (Reshape)        (None, 1, 1, 512)            0         ['global_max_pooling2d_45[0][0\n                                                                    ]']                           \n                                                                                                  \n dense_90 (Dense)            (None, 1, 1, 64)             32832     ['reshape_90[0][0]',          \n                                                                     'reshape_91[0][0]']          \n                                                                                                  \n dense_91 (Dense)            (None, 1, 1, 512)            33280     ['dense_90[0][0]',            \n                                                                     'dense_90[1][0]']            \n                                                                                                  \n add_45 (Add)                (None, 1, 1, 512)            0         ['dense_91[0][0]',            \n                                                                     'dense_91[1][0]']            \n                                                                                                  \n activation_151 (Activation  (None, 1, 1, 512)            0         ['add_45[0][0]']              \n )                                                                                                \n                                                                                                  \n multiply_90 (Multiply)      (None, 16, 16, 512)          0         ['activation_150[0][0]',      \n                                                                     'activation_151[0][0]']      \n                                                                                                  \n lambda_90 (Lambda)          (None, 16, 16, 1)            0         ['multiply_90[0][0]']         \n                                                                                                  \n lambda_91 (Lambda)          (None, 16, 16, 1)            0         ['multiply_90[0][0]']         \n                                                                                                  \n concatenate_68 (Concatenat  (None, 16, 16, 2)            0         ['lambda_90[0][0]',           \n e)                                                                  'lambda_91[0][0]']           \n                                                                                                  \n conv2d_151 (Conv2D)         (None, 16, 16, 1)            98        ['concatenate_68[0][0]']      \n                                                                                                  \n multiply_91 (Multiply)      (None, 16, 16, 512)          0         ['multiply_90[0][0]',         \n                                                                     'conv2d_151[0][0]']          \n                                                                                                  \n average_pooling2d_24 (Aver  (None, 8, 8, 512)            0         ['multiply_91[0][0]']         \n agePooling2D)                                                                                    \n                                                                                                  \n conv2d_152 (Conv2D)         (None, 8, 8, 1024)           4719616   ['average_pooling2d_24[0][0]']\n                                                                                                  \n batch_normalization_103 (B  (None, 8, 8, 1024)           4096      ['conv2d_152[0][0]']          \n atchNormalization)                                                                               \n                                                                                                  \n activation_152 (Activation  (None, 8, 8, 1024)           0         ['batch_normalization_103[0][0\n )                                                                  ]']                           \n                                                                                                  \n conv2d_153 (Conv2D)         (None, 8, 8, 512)            4719104   ['activation_152[0][0]']      \n                                                                                                  \n batch_normalization_104 (B  (None, 8, 8, 512)            2048      ['conv2d_153[0][0]']          \n atchNormalization)                                                                               \n                                                                                                  \n activation_153 (Activation  (None, 8, 8, 512)            0         ['batch_normalization_104[0][0\n )                                                                  ]']                           \n                                                                                                  \n global_average_pooling2d_4  (None, 512)                  0         ['activation_153[0][0]']      \n 6 (GlobalAveragePooling2D)                                                                       \n                                                                                                  \n global_max_pooling2d_46 (G  (None, 512)                  0         ['activation_153[0][0]']      \n lobalMaxPooling2D)                                                                               \n                                                                                                  \n reshape_92 (Reshape)        (None, 1, 1, 512)            0         ['global_average_pooling2d_46[\n                                                                    0][0]']                       \n                                                                                                  \n reshape_93 (Reshape)        (None, 1, 1, 512)            0         ['global_max_pooling2d_46[0][0\n                                                                    ]']                           \n                                                                                                  \n dense_92 (Dense)            (None, 1, 1, 64)             32832     ['reshape_92[0][0]',          \n                                                                     'reshape_93[0][0]']          \n                                                                                                  \n dense_93 (Dense)            (None, 1, 1, 512)            33280     ['dense_92[0][0]',            \n                                                                     'dense_92[1][0]']            \n                                                                                                  \n add_46 (Add)                (None, 1, 1, 512)            0         ['dense_93[0][0]',            \n                                                                     'dense_93[1][0]']            \n                                                                                                  \n activation_154 (Activation  (None, 1, 1, 512)            0         ['add_46[0][0]']              \n )                                                                                                \n                                                                                                  \n multiply_92 (Multiply)      (None, 8, 8, 512)            0         ['activation_153[0][0]',      \n                                                                     'activation_154[0][0]']      \n                                                                                                  \n lambda_92 (Lambda)          (None, 8, 8, 1)              0         ['multiply_92[0][0]']         \n                                                                                                  \n lambda_93 (Lambda)          (None, 8, 8, 1)              0         ['multiply_92[0][0]']         \n                                                                                                  \n concatenate_69 (Concatenat  (None, 8, 8, 2)              0         ['lambda_92[0][0]',           \n e)                                                                  'lambda_93[0][0]']           \n                                                                                                  \n conv2d_154 (Conv2D)         (None, 8, 8, 1)              98        ['concatenate_69[0][0]']      \n                                                                                                  \n multiply_93 (Multiply)      (None, 8, 8, 512)            0         ['multiply_92[0][0]',         \n                                                                     'conv2d_154[0][0]']          \n                                                                                                  \n up_sampling2d_18 (UpSampli  (None, 16, 16, 512)          0         ['multiply_93[0][0]']         \n ng2D)                                                                                            \n                                                                                                  \n concatenate_70 (Concatenat  (None, 16, 16, 1024)         0         ['up_sampling2d_18[0][0]',    \n e)                                                                  'multiply_91[0][0]']         \n                                                                                                  \n conv2d_155 (Conv2D)         (None, 16, 16, 512)          4719104   ['concatenate_70[0][0]']      \n                                                                                                  \n batch_normalization_105 (B  (None, 16, 16, 512)          2048      ['conv2d_155[0][0]']          \n atchNormalization)                                                                               \n                                                                                                  \n activation_155 (Activation  (None, 16, 16, 512)          0         ['batch_normalization_105[0][0\n )                                                                  ]']                           \n                                                                                                  \n conv2d_156 (Conv2D)         (None, 16, 16, 512)          2359808   ['activation_155[0][0]']      \n                                                                                                  \n batch_normalization_106 (B  (None, 16, 16, 512)          2048      ['conv2d_156[0][0]']          \n atchNormalization)                                                                               \n                                                                                                  \n activation_156 (Activation  (None, 16, 16, 512)          0         ['batch_normalization_106[0][0\n )                                                                  ]']                           \n                                                                                                  \n global_average_pooling2d_4  (None, 512)                  0         ['activation_156[0][0]']      \n 7 (GlobalAveragePooling2D)                                                                       \n                                                                                                  \n global_max_pooling2d_47 (G  (None, 512)                  0         ['activation_156[0][0]']      \n lobalMaxPooling2D)                                                                               \n                                                                                                  \n reshape_94 (Reshape)        (None, 1, 1, 512)            0         ['global_average_pooling2d_47[\n                                                                    0][0]']                       \n                                                                                                  \n reshape_95 (Reshape)        (None, 1, 1, 512)            0         ['global_max_pooling2d_47[0][0\n                                                                    ]']                           \n                                                                                                  \n dense_94 (Dense)            (None, 1, 1, 64)             32832     ['reshape_94[0][0]',          \n                                                                     'reshape_95[0][0]']          \n                                                                                                  \n dense_95 (Dense)            (None, 1, 1, 512)            33280     ['dense_94[0][0]',            \n                                                                     'dense_94[1][0]']            \n                                                                                                  \n add_47 (Add)                (None, 1, 1, 512)            0         ['dense_95[0][0]',            \n                                                                     'dense_95[1][0]']            \n                                                                                                  \n activation_157 (Activation  (None, 1, 1, 512)            0         ['add_47[0][0]']              \n )                                                                                                \n                                                                                                  \n multiply_94 (Multiply)      (None, 16, 16, 512)          0         ['activation_156[0][0]',      \n                                                                     'activation_157[0][0]']      \n                                                                                                  \n lambda_94 (Lambda)          (None, 16, 16, 1)            0         ['multiply_94[0][0]']         \n                                                                                                  \n lambda_95 (Lambda)          (None, 16, 16, 1)            0         ['multiply_94[0][0]']         \n                                                                                                  \n concatenate_71 (Concatenat  (None, 16, 16, 2)            0         ['lambda_94[0][0]',           \n e)                                                                  'lambda_95[0][0]']           \n                                                                                                  \n conv2d_157 (Conv2D)         (None, 16, 16, 1)            98        ['concatenate_71[0][0]']      \n                                                                                                  \n multiply_95 (Multiply)      (None, 16, 16, 512)          0         ['multiply_94[0][0]',         \n                                                                     'conv2d_157[0][0]']          \n                                                                                                  \n up_sampling2d_19 (UpSampli  (None, 32, 32, 512)          0         ['multiply_95[0][0]']         \n ng2D)                                                                                            \n                                                                                                  \n concatenate_72 (Concatenat  (None, 32, 32, 768)          0         ['up_sampling2d_19[0][0]',    \n e)                                                                  'multiply_89[0][0]']         \n                                                                                                  \n conv2d_158 (Conv2D)         (None, 32, 32, 256)          1769728   ['concatenate_72[0][0]']      \n                                                                                                  \n batch_normalization_107 (B  (None, 32, 32, 256)          1024      ['conv2d_158[0][0]']          \n atchNormalization)                                                                               \n                                                                                                  \n activation_158 (Activation  (None, 32, 32, 256)          0         ['batch_normalization_107[0][0\n )                                                                  ]']                           \n                                                                                                  \n conv2d_159 (Conv2D)         (None, 32, 32, 256)          590080    ['activation_158[0][0]']      \n                                                                                                  \n batch_normalization_108 (B  (None, 32, 32, 256)          1024      ['conv2d_159[0][0]']          \n atchNormalization)                                                                               \n                                                                                                  \n activation_159 (Activation  (None, 32, 32, 256)          0         ['batch_normalization_108[0][0\n )                                                                  ]']                           \n                                                                                                  \n global_average_pooling2d_4  (None, 256)                  0         ['activation_159[0][0]']      \n 8 (GlobalAveragePooling2D)                                                                       \n                                                                                                  \n global_max_pooling2d_48 (G  (None, 256)                  0         ['activation_159[0][0]']      \n lobalMaxPooling2D)                                                                               \n                                                                                                  \n reshape_96 (Reshape)        (None, 1, 1, 256)            0         ['global_average_pooling2d_48[\n                                                                    0][0]']                       \n                                                                                                  \n reshape_97 (Reshape)        (None, 1, 1, 256)            0         ['global_max_pooling2d_48[0][0\n                                                                    ]']                           \n                                                                                                  \n dense_96 (Dense)            (None, 1, 1, 32)             8224      ['reshape_96[0][0]',          \n                                                                     'reshape_97[0][0]']          \n                                                                                                  \n dense_97 (Dense)            (None, 1, 1, 256)            8448      ['dense_96[0][0]',            \n                                                                     'dense_96[1][0]']            \n                                                                                                  \n add_48 (Add)                (None, 1, 1, 256)            0         ['dense_97[0][0]',            \n                                                                     'dense_97[1][0]']            \n                                                                                                  \n activation_160 (Activation  (None, 1, 1, 256)            0         ['add_48[0][0]']              \n )                                                                                                \n                                                                                                  \n multiply_96 (Multiply)      (None, 32, 32, 256)          0         ['activation_159[0][0]',      \n                                                                     'activation_160[0][0]']      \n                                                                                                  \n lambda_96 (Lambda)          (None, 32, 32, 1)            0         ['multiply_96[0][0]']         \n                                                                                                  \n lambda_97 (Lambda)          (None, 32, 32, 1)            0         ['multiply_96[0][0]']         \n                                                                                                  \n concatenate_73 (Concatenat  (None, 32, 32, 2)            0         ['lambda_96[0][0]',           \n e)                                                                  'lambda_97[0][0]']           \n                                                                                                  \n conv2d_160 (Conv2D)         (None, 32, 32, 1)            98        ['concatenate_73[0][0]']      \n                                                                                                  \n multiply_97 (Multiply)      (None, 32, 32, 256)          0         ['multiply_96[0][0]',         \n                                                                     'conv2d_160[0][0]']          \n                                                                                                  \n up_sampling2d_20 (UpSampli  (None, 64, 64, 256)          0         ['multiply_97[0][0]']         \n ng2D)                                                                                            \n                                                                                                  \n concatenate_74 (Concatenat  (None, 64, 64, 384)          0         ['up_sampling2d_20[0][0]',    \n e)                                                                  'multiply_87[0][0]']         \n                                                                                                  \n conv2d_161 (Conv2D)         (None, 64, 64, 128)          442496    ['concatenate_74[0][0]']      \n                                                                                                  \n batch_normalization_109 (B  (None, 64, 64, 128)          512       ['conv2d_161[0][0]']          \n atchNormalization)                                                                               \n                                                                                                  \n activation_161 (Activation  (None, 64, 64, 128)          0         ['batch_normalization_109[0][0\n )                                                                  ]']                           \n                                                                                                  \n conv2d_162 (Conv2D)         (None, 64, 64, 128)          147584    ['activation_161[0][0]']      \n                                                                                                  \n batch_normalization_110 (B  (None, 64, 64, 128)          512       ['conv2d_162[0][0]']          \n atchNormalization)                                                                               \n                                                                                                  \n activation_162 (Activation  (None, 64, 64, 128)          0         ['batch_normalization_110[0][0\n )                                                                  ]']                           \n                                                                                                  \n up_sampling2d_21 (UpSampli  (None, 128, 128, 128)        0         ['activation_162[0][0]']      \n ng2D)                                                                                            \n                                                                                                  \n concatenate_76 (Concatenat  (None, 128, 128, 192)        0         ['up_sampling2d_21[0][0]',    \n e)                                                                  'multiply_85[0][0]']         \n                                                                                                  \n conv2d_164 (Conv2D)         (None, 128, 128, 64)         110656    ['concatenate_76[0][0]']      \n                                                                                                  \n batch_normalization_111 (B  (None, 128, 128, 64)         256       ['conv2d_164[0][0]']          \n atchNormalization)                                                                               \n                                                                                                  \n activation_164 (Activation  (None, 128, 128, 64)         0         ['batch_normalization_111[0][0\n )                                                                  ]']                           \n                                                                                                  \n conv2d_165 (Conv2D)         (None, 128, 128, 64)         36928     ['activation_164[0][0]']      \n                                                                                                  \n batch_normalization_112 (B  (None, 128, 128, 64)         256       ['conv2d_165[0][0]']          \n atchNormalization)                                                                               \n                                                                                                  \n activation_165 (Activation  (None, 128, 128, 64)         0         ['batch_normalization_112[0][0\n )                                                                  ]']                           \n                                                                                                  \n global_average_pooling2d_5  (None, 64)                   0         ['activation_165[0][0]']      \n 0 (GlobalAveragePooling2D)                                                                       \n                                                                                                  \n global_max_pooling2d_50 (G  (None, 64)                   0         ['activation_165[0][0]']      \n lobalMaxPooling2D)                                                                               \n                                                                                                  \n reshape_100 (Reshape)       (None, 1, 1, 64)             0         ['global_average_pooling2d_50[\n                                                                    0][0]']                       \n                                                                                                  \n reshape_101 (Reshape)       (None, 1, 1, 64)             0         ['global_max_pooling2d_50[0][0\n                                                                    ]']                           \n                                                                                                  \n dense_100 (Dense)           (None, 1, 1, 8)              520       ['reshape_100[0][0]',         \n                                                                     'reshape_101[0][0]']         \n                                                                                                  \n dense_101 (Dense)           (None, 1, 1, 64)             576       ['dense_100[0][0]',           \n                                                                     'dense_100[1][0]']           \n                                                                                                  \n add_50 (Add)                (None, 1, 1, 64)             0         ['dense_101[0][0]',           \n                                                                     'dense_101[1][0]']           \n                                                                                                  \n activation_166 (Activation  (None, 1, 1, 64)             0         ['add_50[0][0]']              \n )                                                                                                \n                                                                                                  \n multiply_100 (Multiply)     (None, 128, 128, 64)         0         ['activation_165[0][0]',      \n                                                                     'activation_166[0][0]']      \n                                                                                                  \n lambda_100 (Lambda)         (None, 128, 128, 1)          0         ['multiply_100[0][0]']        \n                                                                                                  \n lambda_101 (Lambda)         (None, 128, 128, 1)          0         ['multiply_100[0][0]']        \n                                                                                                  \n concatenate_77 (Concatenat  (None, 128, 128, 2)          0         ['lambda_100[0][0]',          \n e)                                                                  'lambda_101[0][0]']          \n                                                                                                  \n conv2d_166 (Conv2D)         (None, 128, 128, 1)          98        ['concatenate_77[0][0]']      \n                                                                                                  \n multiply_101 (Multiply)     (None, 128, 128, 64)         0         ['multiply_100[0][0]',        \n                                                                     'conv2d_166[0][0]']          \n                                                                                                  \n up_sampling2d_22 (UpSampli  (None, 256, 256, 64)         0         ['multiply_101[0][0]']        \n ng2D)                                                                                            \n                                                                                                  \n concatenate_78 (Concatenat  (None, 256, 256, 96)         0         ['up_sampling2d_22[0][0]',    \n e)                                                                  'multiply_83[0][0]']         \n                                                                                                  \n conv2d_167 (Conv2D)         (None, 256, 256, 32)         27680     ['concatenate_78[0][0]']      \n                                                                                                  \n batch_normalization_113 (B  (None, 256, 256, 32)         128       ['conv2d_167[0][0]']          \n atchNormalization)                                                                               \n                                                                                                  \n activation_167 (Activation  (None, 256, 256, 32)         0         ['batch_normalization_113[0][0\n )                                                                  ]']                           \n                                                                                                  \n conv2d_168 (Conv2D)         (None, 256, 256, 32)         9248      ['activation_167[0][0]']      \n                                                                                                  \n batch_normalization_114 (B  (None, 256, 256, 32)         128       ['conv2d_168[0][0]']          \n atchNormalization)                                                                               \n                                                                                                  \n activation_168 (Activation  (None, 256, 256, 32)         0         ['batch_normalization_114[0][0\n )                                                                  ]']                           \n                                                                                                  \n global_average_pooling2d_5  (None, 32)                   0         ['activation_168[0][0]']      \n 1 (GlobalAveragePooling2D)                                                                       \n                                                                                                  \n global_max_pooling2d_51 (G  (None, 32)                   0         ['activation_168[0][0]']      \n lobalMaxPooling2D)                                                                               \n                                                                                                  \n reshape_102 (Reshape)       (None, 1, 1, 32)             0         ['global_average_pooling2d_51[\n                                                                    0][0]']                       \n                                                                                                  \n reshape_103 (Reshape)       (None, 1, 1, 32)             0         ['global_max_pooling2d_51[0][0\n                                                                    ]']                           \n                                                                                                  \n dense_102 (Dense)           (None, 1, 1, 4)              132       ['reshape_102[0][0]',         \n                                                                     'reshape_103[0][0]']         \n                                                                                                  \n dense_103 (Dense)           (None, 1, 1, 32)             160       ['dense_102[0][0]',           \n                                                                     'dense_102[1][0]']           \n                                                                                                  \n add_51 (Add)                (None, 1, 1, 32)             0         ['dense_103[0][0]',           \n                                                                     'dense_103[1][0]']           \n                                                                                                  \n activation_169 (Activation  (None, 1, 1, 32)             0         ['add_51[0][0]']              \n )                                                                                                \n                                                                                                  \n multiply_102 (Multiply)     (None, 256, 256, 32)         0         ['activation_168[0][0]',      \n                                                                     'activation_169[0][0]']      \n                                                                                                  \n lambda_102 (Lambda)         (None, 256, 256, 1)          0         ['multiply_102[0][0]']        \n                                                                                                  \n lambda_103 (Lambda)         (None, 256, 256, 1)          0         ['multiply_102[0][0]']        \n                                                                                                  \n concatenate_79 (Concatenat  (None, 256, 256, 2)          0         ['lambda_102[0][0]',          \n e)                                                                  'lambda_103[0][0]']          \n                                                                                                  \n conv2d_169 (Conv2D)         (None, 256, 256, 1)          98        ['concatenate_79[0][0]']      \n                                                                                                  \n multiply_103 (Multiply)     (None, 256, 256, 32)         0         ['multiply_102[0][0]',        \n                                                                     'conv2d_169[0][0]']          \n                                                                                                  \n conv2d_170 (Conv2D)         (None, 256, 256, 1)          289       ['multiply_103[0][0]']        \n                                                                                                  \n activation_170 (Activation  (None, 256, 256, 1)          0         ['conv2d_170[0][0]']          \n )                                                                                                \n                                                                                                  \n==================================================================================================\nTotal params: 49364314 (188.31 MB)\nTrainable params: 49341914 (188.22 MB)\nNon-trainable params: 22400 (87.50 KB)\n__________________________________________________________________________________________________\nNone\nEpoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"2024-02-26 21:14:58.997070: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_3/dropout_3/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 82\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m==================================\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 82\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[12], line 60\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     52\u001b[0m         checkpoint_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/stacked_model_more_layers_\u001b[39m\u001b[38;5;132;01m{epoch:02d}\u001b[39;00m\u001b[38;5;124m_val_loss_\u001b[39m\u001b[38;5;132;01m{val_loss:.4f}\u001b[39;00m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     53\u001b[0m         model_checkpoint \u001b[38;5;241m=\u001b[39m ModelCheckpoint(checkpoint_path,\n\u001b[1;32m     54\u001b[0m                                    monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     55\u001b[0m                                    save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     56\u001b[0m                                    save_weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     57\u001b[0m                                    mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     58\u001b[0m                                    verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 60\u001b[0m         hist \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNB_EPOCH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;43;03m#                          steps_per_epoch=data_loader.size[0] // batch_size,\u001b[39;49;00m\n\u001b[1;32m     63\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;43;03m#                          validation_steps=data_loader.size[2] // batch_size,\u001b[39;49;00m\n\u001b[1;32m     66\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcsv_logger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_checkpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m TEST:\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m========================================Load Model-s Weights=====================================\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:905\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[1;32m    902\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[1;32m    904\u001b[0m     \u001b[38;5;66;03m# no_variable_creation function.\u001b[39;00m\n\u001b[0;32m--> 905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    909\u001b[0m   bound_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\n\u001b[1;32m    910\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds\n\u001b[1;32m    911\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}